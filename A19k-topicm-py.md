# Topic Modeling with LDA â€“ Python Example 

### ×©×œ×‘ 1: ×˜×¢×™× ×ª ×”×§×•×‘×¥ ×•×‘×“×™×§×ª ×˜×§×¡×˜ ×œ×“×•×’××”

×”××•×“×œ ×™×ª×‘×¡×¡ ×¢×œ ×”×§×•×‘×¥ `npr.csv` ×©××›×™×œ ××¡××›×™ ×˜×§×¡×˜ ×œ× ××ª×•×™×’×™× ×××’×•×•×Ÿ ×ª×—×•××™×  
× ×ª×‘×•× ×Ÿ ×¢×œ ×“×•×’××” ××—×ª ××ª×•×š ×”××¡××›×™× ×›×“×™ ×œ×”×‘×™×Ÿ ××ª ××‘× ×” ×”×˜×§×¡×˜

<img src="ldaex1.jpg" style="width: 100%" />

× ×¡×ª×›×œ ×¢×œ ×”××¡××š ×”×¨××©×•×Ÿ

<img src="ldaex2.jpg" style="width: 100%" />

### ×©×œ×‘ 2: ×•×§×˜×•×¨×™×–×¦×™×” ×‘×××¦×¢×•×ª CountVectorizer

× ×©×ª××© ×‘Ö¾CountVectorizer ×›×“×™ ×œ×”××™×¨ ××ª ×”×˜×§×¡×˜×™× ×œ××˜×¨×™×¦×ª ×ª×›×•× ×•×ª  
× ×©×ª××© ×‘×¤×¨××˜×¨×™×:

- `min_df=2` â†’ ××¡×™×¨ ××™×œ×™× ×©××•×¤×™×¢×•×ª ×‘×¤×—×•×ª ××©× ×™ ××¡××›×™×
- `max_df=0.9` â†’ ××¡×™×¨ ××™×œ×™× ×©××•×¤×™×¢×•×ª ×‘×œ××¢×œ×” ×Ö¾90% ××”××¡××›×™×

<img src="ldaex3.jpg" style="width: 100%" />

### ×©×œ×‘ 3: ××™××•×Ÿ ××•×“×œ LDA

× ×××Ÿ ××ª ×”××•×“×œ ×‘×¢×–×¨×ª ×”××—×œ×§×” `LatentDirichletAllocation` ×Ö¾sklearn

- `n_components=7` â†’ × ×’×“×™×¨ ×©× ×¨×¦×” ×œ×’×œ×•×ª 7 × ×•×©××™×
- `random_state=42` â†’ ×œ×”×‘×˜×™×— ×ª×•×¦××” ×¢×§×‘×™×ª

<img src="ldaex4.jpg" style="width: 100%" />

### ×©×œ×‘ 4: ×‘×“×™×§×ª ×”×ª×¤×œ×’×•×ª ×”×¡×ª×‘×¨×•×™×•×ª ×©×œ ××™×œ×™× ×œ×›×œ × ×•×©×

× ×©×ª××© ×‘××ª×•×“×” `get_feature_names_out` ×›×“×™ ×œ×§×‘×œ ××ª ×¨×©×™××ª ×›×œ ×”×˜×•×§× ×™×  
×•×œ××—×¨ ××›×Ÿ × ×‘×“×•×§ ××ª ×”××˜×¨×™×¦×” ×©× ×•×¦×¨×” â€” ×©×‘×”:

- ×›×œ ×©×•×¨×” ××™×™×¦×’×ª × ×•×©×
- ×›×œ ×¢××•×“×” ××™×™×¦×’×ª ××™×œ×”
- ×”×¢×¨×›×™× ×”× ×”×¡×ª×‘×¨×•×ª ×©×”××™×œ×” ×©×™×™×›×ª ×œ××•×ª×• × ×•×©×

<img src="ldaex5.jpg" style="width: 100%" />

<img src="ldaex6.jpg" style="width: 100%" />

<img src="ldaex7.jpg" style="width: 100%" />

### ×©×œ×‘ 5: ××™×ª×•×¨ ×”××™×œ×™× ×”×—×–×§×•×ª ×‘×™×•×ª×¨ ×œ×›×œ × ×•×©×

× ×©×ª××© ×‘Ö¾`np.argsort()` ×›×“×™ ×œ×¡×“×¨ ××ª ×›×œ ×”××™×œ×™× ×œ×¤×™ ×”×”×¡×ª×‘×¨×•×ª ×©×œ×”×Ÿ  
×•× ×‘×—×¨ ××ª **10 ×”××™×œ×™× ×¢× ×”×”×¡×ª×‘×¨×•×ª ×”×’×‘×•×”×” ×‘×™×•×ª×¨ ×œ×›×œ Topic**

×›×š × ×•×›×œ **×œ× ×¡×•×ª ×œ×ª×ª ×©× ×œ× ×•×©× ×œ×¤×™ ×”××™×œ×™× ×©××™×™×¦×’×•×ª ××•×ª×•**  
×œ×“×•×’××”: × ×•×©× 1 ××›×™×œ ××™×œ×™× ×©×§×©×•×¨×•×ª ×œÖ¾Politics â†’ × ×™×ª×Ÿ ×œ×ª×™×™×’ ××•×ª×• ×›Ö¾"×‘×—×™×¨×•×ª"

<img src="ldaex6.jpg" style="width: 100%" />

### ×©×œ×‘ 6: ×©×™×•×š × ×•×©× ×œ×›×œ ××¡××š

×œ×‘×¡×•×£, × ×’×“×™×¨ ×¢××•×“×” ×—×“×©×” ×‘Ö¾DataFrame ×¢× ×”×©×™×•×š ×œ× ×•×©× ×”×›×™ ×¡×‘×™×¨  
× ×©×ª××© ×‘Ö¾`.argmax(axis=1)` ×¢×œ ××˜×¨×™×¦×ª ×”×ª×•×¦××•×ª ×›×“×™ ×œ×©×™×™×š ×›×œ ××¡××š ×œ× ×•×©× ×‘×¢×œ ×”×”×¡×ª×‘×¨×•×ª ×”×’×‘×•×”×” ×‘×™×•×ª×¨

ğŸ“· **×”×•×¡×£ ×ª××•× ×” ××¢××•×“ 33**

## ×”×§×•×“ ×”××œ×

```python
# Load the data
import pandas as pd
import numpy as np

df = pd.read_csv('npr.csv')
df.head()

# Look at a specific document
df['Article'][0]

# Feature extraction with count vectorization
from sklearn.feature_extraction.text import CountVectorizer

X = df['Article']
count_vectorizer = CountVectorizer(max_df=0.9, min_df=2, stop_words='english')
X_counts = count_vectorizer.fit_transform(X)

# Train the LDA model
from sklearn.decomposition import LatentDirichletAllocation

lda_model = LatentDirichletAllocation(n_components=7, random_state=101)
lda_model.fit(X_counts)

# Examine the count vectorizer tokens
print(len(count_vectorizer.get_feature_names_out()))
print(type(count_vectorizer.get_feature_names_out()))

# Check the LDA model components
lda_model.components_.shape

# Look at the components (probabilities of tokens for each topic)
lda_model.components_

# Example of using np.argsort
array = np.array([10, 2, 5])
np.argsort(array)

# Get the top 10 tokens for the first topic
first_topic = lda_model.components_[0]
np.argsort(first_topic)[-10:]

# Get the top 10 tokens for each topic
for topic_idx, topic in enumerate(lda_model.components_):
    topic_token_array = []
    for index in topic.argsort()[-10:]:
        topic_token_array.append(count_vectorizer.get_feature_names_out()[index])
    print(f"Topic number {topic_idx} - Top 10 tokens:")
    print(topic_token_array)
    print()

# Get the topic distribution for the documents
topic_results = lda_model.transform(X_counts)
topic_results[0]  # Probability distribution for the first document

# Assign the most likely topic to each document
df['topic'] = topic_results.argmax(axis=1)
df.head()
```