# NLP FETAURES

# מהו 🧠 Text Classification – סיווג טקסטים

## מה זה סיווג טקסטים

סיווג טקסטים (Text Classification) הוא משימה מרכזית בתחום עיבוד שפה טבעית (NLP)  
במשימה זו מקצים לכל טקסט תגית אחת או יותר מתוך רשימת קטגוריות ידועה מראש

דוגמאות לקטגוריות נפוצות:
- חיובי / שלילי (Sentiment Analysis)
- ספאם / לא ספאם
- נושאים: ספורט, פוליטיקה, טכנולוגיה ועוד

## רכיבים עיקריים בתהליך

- **Labels / Categories** – הקבוצות האפשריות שהטקסט יכול להשתייך אליהן  
- **Features** – מאפיינים המופקים מהטקסט לצורך סיווג (כמו תדירות מילים או תכונות תחביריות)  
- **Model** – אלגוריתם לומד (כמו Naive Bayes, SVM או מודלים עמוקים) שמקבל את המאפיינים ומחזיר תחזית לסיווג

## ✨ Feature Extraction – הפקת מאפיינים מהטקסט

כדי שנוכל להשתמש בטקסט במודל למידת מכונה, עלינו להמיר אותו לייצוג מספרי  
נשתמש בטכניקות שונות ל־Feature Extraction

### טכניקות נפוצות:

- Tokenization – חלוקה למילים
- Bag of Words (BoW) – מונה כמה פעמים כל מילה מופיעה
- TF-IDF – מדגיש מילים נדירות יחסית למסמך
- POS Tagging – זיהוי חלקי דיבר
- NER – זיהוי ישויות

## 🧰 BoW – Bag of Words

BoW היא שיטה פשוטה שבה בונים אוסף של כל המילים הייחודיות מהמסמכים  
לאחר מכן יוצרים מטריצה בה כל שורה היא מסמך, וכל עמודה היא מילה מהאוסף  
התאים מציינים כמה פעמים מילה הופיעה במסמך

דוגמה:

- Document 1: "I love NLP"  
- Document 2: "NLP is fun"

Vocabulary: ["I", "love", "NLP", "is", "fun"]

|       | I | love | NLP | is | fun |
|-------|---|------|-----|----|-----|
| Doc1  | 1 | 1    | 1   | 0  | 0   |
| Doc2  | 0 | 0    | 1   | 1  | 1   |

📌 שיטה זו מתעלמת מסדר המילים ומתמקדת רק בספירה

## 🧠 TF-IDF – Term Frequency-Inverse Document Frequency

השיטה הזו משפרת את BoW על ידי הדגשת מילים נדירות  
היא כוללת 2 שלבים:

1. TF – תדירות המילה במסמך  
2. IDF – הופכיות תדירות המילה בכלל המסמכים  
3. TF * IDF – נותן ציון סופי למילה במסמך

דוגמה:

- Document 1: "I love NLP"  
- Document 2: "NLP is fun"

TF:
- NLP מופיעה פעם אחת מתוך 3 מילים בכל מסמך → TF = 1/3

IDF:
- NLP מופיעה בשני המסמכים → IDF = log(2/2) = 0  
- I מופיעה רק במסמך 1 → IDF = log(2/1) = 0.301

TF-IDF:
- NLP → 1/3 * 0 = 0  
- I → 1/3 * 0.301 ≈ 0.1003

|       | I      | love   | NLP | is     | fun    |
|-------|--------|--------|-----|--------|--------|
| Doc1  | 0.1003 | 0.1003 | 0   | 0      | 0      |
| Doc2  | 0      | 0      | 0   | 0.1003 | 0.1003 |

