## מה זה TensorFlow

<img src="deepex2.jpg" style="width: 15%" align="right" />

טנסר-פלואו היא ספריית קוד פתוח מבית Google  
היא נועדה לעזור לנו לבנות מודלים של למידת מכונה ובעיקר רשתות נוירונים  
הספרייה מאוד חזקה וגמישה ומשמשת הרבה מאוד בתחומים כמו ראיית מחשב, עיבוד שפה, חיזוי ועוד

## למה להשתמש ב־TensorFlow

- מאפשרת לבנות רשתות נוירונים בצורה קלה או מתקדמת  
- תומכת גם ב־CPU וגם ב־GPU כך שאפשר לעבוד מהר יותר  
- מתחברת בצורה נוחה עם ספריות אחרות כמו NumPy  
- יש לה קהילה מאוד גדולה והמון מדריכים ודוגמאות באינטרנט  
- אפשר להריץ את המודלים גם על מובייל וגם על שרתים

## איך מתקינים את TensorFlow

בשורת הפקודה או ב־Jupyter מריצים

```
pip install tensorflow
```

לאחר ההתקנה אפשר לבדוק שהספרייה קיימת בעזרת

```python
import tensorflow as tf
print(tf.__version__)
```

## איך מתחילים לעבוד עם TensorFlow

לרוב אנחנו נשתמש בממשק שנקרא `Keras` שנמצא בתוך TensorFlow  
הממשק הזה מאפשר לנו לבנות מודלים בצורה פשוטה ונוחה גם למתחילים

אנחנו יכולים ליצור רשת נוירונים על ידי הגדרה של שכבות  
למשל רשת פשוטה עם שכבת קלט אחת שכבת חבויה אחת ושכבת פלט אחת תיראה כך

```python
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

model = Sequential()  # יצירת מודל ריק
model.add(Dense(10, activation='relu'))  # שכבת חבויה עם 10 נוירונים ו־ReLU
model.add(Dense(1, activation='sigmoid'))  # שכבת פלט עם נוירון אחד ו־Sigmoid
```

## תהליך עבודה כללי עם TensorFlow

### שלב 1 – טעינת הנתונים והכנה

אנחנו מתחילים בטעינה של קובץ הנתונים אל תוך pandas  
לאחר מכן מבצעים פעולות ניקוי כמו המרת עמודות טקסט לערכים מספריים  
בנוסף מבצעים סטנדרטיזציה כדי שכל הערכים יהיו בטווח אחיד

### שלב 2 – בניית המודל

אנחנו יוצרים את המודל באמצעות מחלקת `Sequential`  
ומוסיפים לו שכבות `Dense` עם מספר נוירונים ופונקציית הפעלה לכל שכבה

### שלב 3 – קומפילציה של המודל

כאן אנחנו קובעים איך המודל ילמד  
אנחנו בוחרים optimizer כמו `sgd` או `adam`  
וגם פונקציית הפסד כמו `binary_crossentropy` או `mse` לפי סוג הבעיה

### שלב 4 – אימון המודל

אנחנו מאמנים את המודל באמצעות הפונקציה `fit`  
קובעים כמה שורות יהיו בכל חבילה באמצעות `batch_size`  
וגם כמה פעמים המודל יעבור על כל הנתונים באמצעות `epochs`

### שלב 5 – בדיקה וחיזוי

לאחר סיום האימון נבחן את הביצועים של המודל על קבוצת הטסט  
נשתמש במדדים כמו `accuracy` או `confusion matrix`  
נוכל גם להזין למודל לקוחות חדשים ולראות את התחזית שהוא מחזיר

---

## דוגמה של בניית מודל ANN בפייתון

### קובץ הנתונים – Churn_Modelling.csv

מדובר בקובץ שמכיל מידע על לקוחות של בנק  
לכל שורה יש מידע כמו גיל מגדר מדינה אם יש לו כרטיס אשראי יתרה ועוד  
יש גם עמודה בשם `Exited` שאומרת אם הלקוח עזב את הבנק או נשאר  
המטרה שלנו היא לחזות בעזרת רשת נוירונים אם לקוח עתידי יעזוב את הבנק או לא

<img src="deepex1.jpg" style="width: 100%" />

## שלב 1 – בניית קבוצות של נתונים

אנחנו מפרידים את הנתונים לשתי קבוצות עיקריות  
X זה כל הנתונים שמהם המודל ילמד  
y זו העמודה שאנחנו מנסים לחזות  
כמו כן אנחנו מוחקים עמודות מזהות שלא עוזרות ללמידה כמו מספר שורה ושם משפחה

## שלב 2 – טיפול בעמודות קטגוריות

יש עמודות שמכילות טקסטים כמו מגדר או מדינה  
בשביל שמכונה תוכל להבין את זה אנחנו ממירים את הטקסטים למספרים  
זה נקרא One Hot Encoding – הופכים כל ערך בעמודה לעמודה חדשה עם ערכים 0 או 1

לדוגמה  
המגדר Male הופך לעמודה Gender_Male  
המדינות France Spain Germany יהפכו לשלוש עמודות נפרדות

## שלב 3 – פיצול ל־Train ו־Test

אנחנו מחלקים את הנתונים לשני חלקים  
Train זו הקבוצה שעליה המודל לומד  
Test זו הקבוצה שעליה בודקים את הביצועים של המודל

## שלב 4 – סטנדרטיזציה

לפני שמתחילים לבנות את המודל עושים סטנדרטיזציה לנתונים  
כלומר ממירים את הערכים כך שיהיו בממוצע אפס וסטיית תקן אחת  
זה חשוב מאוד ברשתות נוירונים כדי לאזן את השפעת כל פיצ'ר

## שלב 5 – בניית רשת הנוירונים ANN

הרשת מורכבת משכבות  
שכבת קלט מעבירה את המידע הגולמי  
שכבת חבויה מבצעת את הלמידה והחישובים  
שכבת פלט נותנת את התוצאה אם הלקוח יעזוב

במקרה הזה  
יש שכבת חבויה אחת עם עשרה נוירונים  
פונקציית ההפעלה שלה היא ReLU שמתאימה ללמידה כללית  
שכבת הפלט מכילה נוירון אחד עם פונקציית הפעלה Sigmoid שמתאימה לסיווג בינארי

## שלב 6 – קומפילציה של המודל

אנחנו צריכים להגדיר למודל שלושה דברים  
Optimizer זה האלגוריתם שמעדכן את המשקלים לדוגמה SGD  
Loss זו פונקציית הפסד שהמודל מנסה למזער לדוגמה binary_crossentropy  
Metrics אלו מדדים שבודקים את הביצועים של המודל לדוגמה accuracy

## שלב 7 – אימון Training

המודל מתאמן על הנתונים למשך מספר איטרציות שנקראות epochs  
בכל איטרציה הוא מעדכן את המשקלים ומנסה לדייק יותר  
אנחנו בוחרים גם גודל חבילה batch_size כלומר כמה שורות יתעדכנו יחד בכל פעם  
במקרה הזה batch_size שווה ל־32 ו־epochs שווה ל־100

שים פה את התמונה משקף 29 כדי לראות את תהליך האימון בלוגים

## שלב 8 – חיזוי על טסט חדש

בסיום האימון בודקים איך המודל חוזה תוצאות על קבוצת הטסט  
הוא נותן ערכים בין אפס לאחת שמייצגים הסתברות  
כדי לקבל תשובה בינארית אמיתית קובעים סף לרוב 0.5  
אם הערך מעל זה נחשב לאחד אחרת זה אפס

## שלב 9 – חיזוי על לקוח חדש

אפשר להזין למודל גם לקוח חדש שמעולם לא ראה  
מכינים שורה עם ערכי הלקוח כמו גיל מגדר יתרה וכדומה  
עושים עליה סטנדרטיזציה באותו אופן שעשינו קודם  
מפעילים את המודל ומקבלים ניבוי אם הלקוח יעזוב או לא

## מושגים נוספים שכדאי להכיר

### Activation Function

פונקציה מתמטית שעוזרת לנוירון להחליט מה הפלט שלו  
היא יוצרת אי לינאריות בלמידה בלעדיה המודל יתנהג כמו רגרסיה פשוטה  
דוגמאות נפוצות הן ReLU Sigmoid Tanh ו־Softmax

### Loss Function

מודד כמה המודל טעה בניבוי  
בבעיות סיווג משתמשים בפונקציות כמו binary_crossentropy או categorical_crossentropy

### Optimizer

שיטה שבה המודל משפר את עצמו על ידי עדכון המשקלים  
הנפוצים ביותר הם SGD Adam RMSprop
