# KNN - ×ª×¨×—×™×©×™ ×ª×™×§×• ×•×©×™×˜×•×ª ××ª×§×“××•×ª

## ×˜×™×¤×•×œ ×‘××§×¨×™ ×ª×™×§×•

××—×ª ×”×‘×¢×™×•×ª ×©×¢×œ×•×œ×•×ª ×œ×”×ª×¢×•×¨×¨ ×‘××œ×’×•×¨×™×ª× KNN ×”×™× ×›××©×¨ ×§×™×™× ×ª×™×§×• (tie) ×‘×™×Ÿ ××¡×¤×¨ ×§×˜×’×•×¨×™×•×ª. ××¦×‘ ×–×” ××ª×¨×—×© ×›××©×¨ K ×©×›× ×™× ××ª×—×œ×§×™× ×‘××•×¤×Ÿ ×©×•×•×” ×‘×™×Ÿ ×©×ª×™ ×§×˜×’×•×¨×™×•×ª ××• ×™×•×ª×¨.

**×“×•×’××”**: × × ×™×— ×©×‘×—×¨× ×• K=4 ×•××¦×× ×• ×©××ª×•×š ××¨×‘×¢×ª ×”×©×›× ×™× ×”×§×¨×•×‘×™× ×‘×™×•×ª×¨, 2 ×”× ×ª×¤×•×—×™× ×•-2 ×”× ×ª×¤×•×–×™×. ××™×š × ×—×œ×™×˜ ×œ××™×–×• ×§×˜×’×•×¨×™×” ×œ×¡×•×•×’ ××ª ×”×¤×¨×™ ×”×—×“×©?

### ××¡×˜×¨×˜×’×™×•×ª ×œ×˜×™×¤×•×œ ×‘×ª×™×§×•:

1. **×‘×—×™×¨×ª K ××™-×–×•×’×™**: ×”×©×™×˜×” ×”×¤×©×•×˜×” ×‘×™×•×ª×¨ ×”×™× ×œ×”×©×ª××© ×‘-K ××™-×–×•×’×™ (3, 5, 7, ×•×›×•') ×›×“×™ ×œ×× ×•×¢ ×ª×™×§×• ××œ×›×ª×—×™×œ×”. ×–×” ×¢×•×‘×“ ×”×™×˜×‘ ×¢×‘×•×¨ ×‘×¢×™×•×ª ×¡×™×•×•×’ ×‘×™× ××¨×™ (×©×ª×™ ×§×˜×’×•×¨×™×•×ª).

2. **×©×§×œ×•×œ ×œ×¤×™ ××¨×—×§**: ×‘××§×•× ×œ×ª×ª ×œ×›×œ ×©×›×Ÿ ××©×§×œ ×–×”×”, × ×©×§×œ×œ ××ª ×”×§×‘×•×¦×” ×©×œ ×”× ×§×•×“×” ×œ×¤×™ 1 ×—×œ×§×™ d, ×›××©×¨ d ×”×•× ×”××¨×—×§ ××”× ×§×•×“×” ×”×—×“×©×”. ×›×š, ×©×›× ×™× ×§×¨×•×‘×™× ×™×•×ª×¨ ××§×‘×œ×™× ×”×©×¤×¢×” ×’×“×•×œ×” ×™×•×ª×¨:

$$\text{××©×§×œ ×”×©×›×Ÿ} = \frac{1}{d(x, x_i)}$$

×“×•×’××” ××¡×¤×¨×™×ª â€“×œ×¤×™ 

$$
\frac{1}{d}
$$

× × ×™×— ×©×”×©×ª××©× ×• ×‘-K=4 ×•×”×©×›× ×™× ×”×§×¨×•×‘×™× ×‘×™×•×ª×¨ ×œ×¤×¨×™ ×—×“×© ×”×:

| Neighbor | Class     | Distance from new fruit \( d \) | Weight \( \frac{1}{d} \) |
|----------|-----------|-------------------------------|--------------------------|
| 1        | Apple ğŸ   | 1.0                           | 1.00                     |
| 2        | Apple ğŸ   | 2.0                           | 0.50                     |
| 3        | Orange ğŸŠ  | 3.0                           | 0.33                     |
| 4        | Orange ğŸŠ  | 4.0                           | 0.25                     |

- **×ª×¤×•×— ğŸ**:  
  \( 1.00 + 0.50 = 1.50 \)

- **×ª×¤×•×– ğŸŠ**:  
  \( 0.33 + 0.25 = 0.58 \)


âœ… ××¡×§× ×”:

×œ××¨×•×ª ×©×™×© ×ª×™×§×• ×‘××¡×¤×¨ ×”×§×˜×’×•×¨×™×•×ª (2 ×ª×¤×•×—×™×, 2 ×ª×¤×•×–×™×),  
×›××©×¨ ××‘×¦×¢×™× ×©×§×œ×•×œ ×œ×¤×™ ×”××¨×—×§ â€“ ×”×©×›× ×™× ×”×§×¨×•×‘×™× ××©×¤×™×¢×™× ×™×•×ª×¨,  
×•×œ×›×Ÿ ×”×§×˜×’×•×¨×™×” **×ª×¤×•×—** ×× ×¦×—×ª

3. **×”×•×¨×“×ª K ×‘-1**: ×× ××ª×¨×—×© ×ª×™×§×•, × ×™×ª×Ÿ ×œ×”×§×˜×™×Ÿ ××ª K ×‘××•×¤×Ÿ ×–×× ×™ ×‘-1 ×•×œ×‘×“×•×§ ×× ×”×ª×™×§×• × ×¤×ª×¨.

4. **×”×¢×“×¤×ª ×§×˜×’×•×¨×™×”**: ×× ×™×© ×¡×™×‘×” ×œ×•×’×™×ª ×œ×”×¢×“×™×£ ×§×˜×’×•×¨×™×” ××¡×•×™××ª (×œ××©×œ ×§×˜×’×•×¨×™×” ×©×›×™×—×” ×™×•×ª×¨), × ×™×ª×Ÿ ×œ×”×©×ª××© ×‘×” ×›××›×¨×™×¢×” ×‘××§×¨×™ ×ª×™×§×•.

5. **×‘×—×™×¨×” ××§×¨××™×ª**: ×‘×—×™×¨×” ××§×¨××™×ª ×©×œ ××—×ª ××”×§×˜×’×•×¨×™×•×ª ×”×©×•×•×ª.

×“×•×’××ª ×§×•×“ ×œ×˜×™×¤×•×œ ×‘×ª×™×§×• ×‘×××¦×¢×•×ª ×©×§×œ×•×œ ××¨×—×§×™×:

```python
def weighted_knn_predict(X_train, y_train, x_new, k):
    # ×—×™×©×•×‘ ××¨×—×§×™× ×‘×™×Ÿ ×”× ×§×•×“×” ×”×—×“×©×” ×œ×›×œ × ×§×•×“×•×ª ×”××™××•×Ÿ
    distances = []
    for i, x_train in enumerate(X_train):
        dist = np.sqrt(np.sum((x_train - x_new) ** 2))
        distances.append((dist, i))
    
    # ××™×•×Ÿ ×”××¨×—×§×™× ×•×‘×—×™×¨×ª K ×”×§×¨×•×‘×™× ×‘×™×•×ª×¨
    distances.sort()
    k_nearest = distances[:k]
    
    # ×©×§×œ×•×œ ×”×¦×‘×¢×•×ª ×œ×¤×™ ×”××¨×—×§
    class_votes = {}
    for dist, idx in k_nearest:
        weight = 1.0 / max(dist, 0.000001)  # ×× ×™×¢×ª ×—×œ×•×§×” ×‘××¤×¡
        vote = y_train[idx]
        
        if vote in class_votes:
            class_votes[vote] += weight
        else:
            class_votes[vote] = weight
    
    # ×‘×—×™×¨×ª ×”×§×˜×’×•×¨×™×” ×¢× ×”×¦×™×•×Ÿ ×”××©×•×§×œ×œ ×”×’×‘×•×” ×‘×™×•×ª×¨
    return max(class_votes.items(), key=lambda x: x[1])[0]
```

## ××“×“×™ ×”×¢×¨×›×”: Precision, Recall, F1, Support

×œ×”×¢×¨×›×ª ×‘×™×¦×•×¢×™ ××•×“×œ KNN, ××©×ª××©×™× ×‘×›××” ××“×“×™× ×¡×˜× ×“×¨×˜×™×™×:

### 1. Precision (×“×™×•×§)
××•×“×“ ××ª ××—×•×– ×”× ×™×‘×•×™×™× ×”×—×™×•×‘×™×™× ×©×”×™×• × ×›×•× ×™× ×‘×××ª:

$$\text{Precision} = \frac{TP}{TP + FP}$$

×›××©×¨:
- TP (True Positive): ×—×™×–×•×™ ×—×™×•×‘×™ × ×›×•×Ÿ
- FP (False Positive): ×—×™×–×•×™ ×—×™×•×‘×™ ×©×’×•×™

×“×™×•×§ ×’×‘×•×” ××©××¢×•×ª×• ×©×›××©×¨ ×”××•×“×œ ×× ×‘× '×›×Ÿ', ×”×•× ×‘×“×¨×š ×›×œ×œ ×¦×•×“×§.

### 2. Recall (×›×™×¡×•×™ ××• ×¨×’×™×©×•×ª)
××•×“×“ ××™×–×” ××—×•×– ××”××§×¨×™× ×”×—×™×•×‘×™×™× ×‘×××ª ×”××•×“×œ ×”×¦×œ×™×— ×œ×–×”×•×ª:

$$\text{Recall} = \frac{TP}{TP + FN}$$

×›××©×¨:
- FN (False Negative): ×—×™×–×•×™ ×©×œ×™×œ×™ ×©×’×•×™

×›×™×¡×•×™ ×’×‘×•×” ××©××¢×•×ª×• ×©×”××•×“×œ ××–×”×” ××ª ×¨×•×‘ ×”××§×¨×™× ×”×—×™×•×‘×™×™× ×”×××™×ª×™×™×.

### 3. F1 Score
×××•×¦×¢ ×”×¨××•× ×™ ×©×œ Precision ×•-Recall, ×××–×Ÿ ×‘×™×Ÿ ×©× ×™ ×”××“×“×™×:

$$\text{F1} = 2 \cdot \frac{\text{Precision} \cdot \text{Recall}}{\text{Precision} + \text{Recall}}$$

F1 ×’×‘×•×” ××©×§×£ ××™×–×•×Ÿ ×˜×•×‘ ×‘×™×Ÿ ×“×™×•×§ ×œ×›×™×¡×•×™.

### 4. Support
××¡×¤×¨ ×”××•×¤×¢×™× ×‘×¤×•×¢×œ ×©×œ ×›×œ ×§×˜×’×•×¨×™×” ×‘×§×‘×•×¦×ª ×”×‘×“×™×§×”.

### ×“×•×’××” ××˜×¨×™×¦×ª ×‘×œ×‘×•×œ (Confusion Matrix):

```
                  | ×¦×¤×•×™: ×ª×¤×•×— | ×¦×¤×•×™: ×ª×¤×•×– | ×¦×¤×•×™: ×‘× × ×”
-------------------|------------|------------|------------
×××™×ª×™: ×ª×¤×•×—      |     14     |     2      |     1
×××™×ª×™: ×ª×¤×•×–      |      3     |    16      |     0
×××™×ª×™: ×‘× × ×”      |      0     |     1      |    13
```

×•×—×™×©×•×‘ ×”××“×“×™×:

```
              precision    recall  f1-score   support
       ×ª×¤×•×—      0.82      0.82      0.82        17
       ×ª×¤×•×–      0.84      0.84      0.84        19
       ×‘× × ×”      0.93      0.93      0.93        14

    accuracy                          0.86        50
   macro avg      0.86      0.86      0.86        50
weighted avg      0.86      0.86      0.86        50
```

×§×•×“ ×¤×™×™×ª×•×Ÿ ×œ×”×¦×’×ª ××“×“×™ ×‘×™×¦×•×¢:

```python
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

# ××™××•×Ÿ ×”××•×“×œ
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
model = KNeighborsClassifier(n_neighbors=3)
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

# ×”×¦×’×ª ××˜×¨×™×¦×ª ×”×‘×œ×‘×•×œ ×‘×¦×•×¨×” ×’×¨×¤×™×ª
plt.figure(figsize=(8, 6))
cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
            xticklabels=model.classes_, 
            yticklabels=model.classes_)
plt.title('Confusion Matrix')
plt.ylabel('Actual')
plt.xlabel('Predicted')
plt.show()

# ×”×¦×’×ª ×“×•×— ×¡×™×•×•×’ ××¤×•×¨×˜
print(classification_report(y_test, y_pred))
```

## ×©×™×˜×•×ª ×œ×‘×—×™×¨×ª K ××•×¤×˜×™××œ×™

### 1. Elbow Method

×©×™×˜×ª ×”-Elbow ××‘×•×¡×¡×ª ×¢×œ ×‘×“×™×§×ª ×©×™×¢×•×¨ ×”×©×’×™××” ×©×œ ×”××•×“×œ ×¢× ×¢×¨×›×™ K ×©×•× ×™×, ×•×—×™×¤×•×© × ×§×•×“×ª "××¨×¤×§" ×©×‘×” ×ª×•×¡×¤×ª ×¢×¨×›×™ K × ×•×¡×¤×™× ××™× ×” ××©×¤×¨×ª ××©××¢×•×ª×™×ª ××ª ×”×‘×™×¦×•×¢×™×:

```python
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt
import numpy as np

# ×”×›× ×ª ×”× ×ª×•× ×™×
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# ×‘×“×™×§×ª ×“×™×•×§ ×¢×‘×•×¨ ×¢×¨×›×™ K ×©×•× ×™×
k_range = range(1, 31)
scores = []

for k in k_range:
    model = KNeighborsClassifier(n_neighbors=k)
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    scores.append(accuracy_score(y_test, y_pred))

# ×”×¦×’×ª ×”×ª×•×¦××•×ª ×‘×’×¨×£
plt.figure(figsize=(10, 6))
plt.plot(k_range, scores, marker='o')
plt.title('KNN: Accuracy for different K values')
plt.xlabel('K Value')
plt.ylabel('Accuracy')
plt.xticks(k_range[::2])  # ×”×¦×’×ª ×¢×¨×›×™ K ×–×•×’×™×™× ×‘×œ×‘×“ ×œ× ×•×—×•×ª
plt.grid(True)
plt.show()

# ××¦×™××ª ×¢×¨×š K ×”××•×¤×˜×™××œ×™
optimal_k = k_range[np.argmax(scores)]
print(f"×¢×¨×š K ×”××•×¤×˜×™××œ×™ ×”×•×: {optimal_k} ×¢× ×“×™×•×§ ×©×œ: {max(scores):.4f}")
```

<img src="elbow_method.png" style="width:60%;"/>

×‘×©×™×˜×ª ×”-Elbow, ×× ×• ××—×¤×©×™× ××ª ×”× ×§×•×“×” ×©×‘×” ×”×©×™×¤×•×¨ ×‘×“×™×•×§ ××ª×—×™×œ ×œ×”×ª××ª×Ÿ ××©××¢×•×ª×™×ª, ×›××• "××¨×¤×§" ×‘×’×¨×£.

### 2. Cross-Validation (××™××•×ª ×¦×•×œ×‘)

××™××•×ª ×¦×•×œ×‘ ××—×œ×§ ××ª ×”× ×ª×•× ×™× ×œ××¡×¤×¨ "×§×™×¤×•×œ×™×" (folds), ×•××‘×¦×¢ ××™××•×Ÿ ×•× ×™×‘×•×™ ×¢×œ ×›×œ ×§×™×¤×•×œ, ×××¦×¢ ××ª ×”×ª×•×¦××•×ª ×›×“×™ ×œ×§×‘×œ ×”×¢×¨×›×” ××“×•×™×§×ª ×™×•×ª×¨ ×©×œ ×‘×™×¦×•×¢×™ ×”××•×“×œ:

```python
from sklearn.model_selection import cross_val_score

# ×‘×“×™×§×ª ×‘×™×¦×•×¢×™× ×¢× ××™××•×ª ×¦×•×œ×‘ ×¢×‘×•×¨ ×¢×¨×›×™ K ×©×•× ×™×
k_range = range(1, 31)
cv_scores = []

for k in k_range:
    model = KNeighborsClassifier(n_neighbors=k)
    scores = cross_val_score(model, X, y, cv=10, scoring='accuracy')  # 10-fold CV
    cv_scores.append(scores.mean())

# ×”×¦×’×ª ×”×ª×•×¦××•×ª ×‘×’×¨×£
plt.figure(figsize=(10, 6))
plt.plot(k_range, cv_scores, marker='o')
plt.title('KNN: CV Accuracy for different K values')
plt.xlabel('K Value')
plt.ylabel('CV Accuracy')
plt.xticks(k_range[::2])
plt.grid(True)
plt.show()

# ××¦×™××ª ×¢×¨×š K ×”××•×¤×˜×™××œ×™
optimal_k_cv = k_range[np.argmax(cv_scores)]
print(f"×¢×¨×š K ×”××•×¤×˜×™××œ×™ (CV) ×”×•×: {optimal_k_cv} ×¢× ×“×™×•×§ ×××•×¦×¢ ×©×œ: {max(cv_scores):.4f}")
```

<img src="cross_validation.png" style="width:60%;"/>

### ×”×©×•×•××” ×‘×™×Ÿ ×©×™×˜×•×ª ×‘×—×™×¨×ª K

```python
from sklearn.model_selection import GridSearchCV

# ×”×’×“×¨×ª ×¤×¨××˜×¨×™× ×œ×—×™×¤×•×©
param_grid = {'n_neighbors': list(range(1, 31))}

# ×©×™××•×© ×‘-GridSearchCV ×œ×—×™×¤×•×© ××•×˜×•××˜×™
grid_search = GridSearchCV(KNeighborsClassifier(), param_grid, cv=10)
grid_search.fit(X, y)

# ×”×¦×’×ª ×ª×•×¦××•×ª ×”×—×™×¤×•×©
print(f"×¢×¨×š K ×”××•×¤×˜×™××œ×™ (GridSearchCV): {grid_search.best_params_['n_neighbors']}")
print(f"×“×™×•×§ ××™×˜×‘×™: {grid_search.best_score_:.4f}")

# ×”×©×•×•××ª ×›×œ ×”×©×™×˜×•×ª
plt.figure(figsize=(12, 6))
plt.plot(k_range, scores, marker='o', label='Test Accuracy')
plt.plot(k_range, cv_scores, marker='s', label='CV Accuracy')
plt.axvline(x=optimal_k, color='r', linestyle='--', label=f'Best K (Test): {optimal_k}')
plt.axvline(x=optimal_k_cv, color='g', linestyle='--', label=f'Best K (CV): {optimal_k_cv}')
plt.axvline(x=grid_search.best_params_['n_neighbors'], color='m', linestyle='--', 
            label=f"Best K (GridSearchCV): {grid_search.best_params_['n_neighbors']}")
plt.title('Comparison of Methods for Selecting Optimal K')
plt.xlabel('K Value')
plt.ylabel('Accuracy')
plt.xticks(k_range[::2])
plt.legend()
plt.grid(True)
plt.show()
```

<img src="k_comparison.png" style="width:60%;"/>

### ×›×™×¦×“ ×œ×‘×—×•×¨ ××ª K ×”××ª××™×?

1. **×’×•×“×œ ×”××“×’×**: ×›×›×œ ×©××“×’× ×”××™××•×Ÿ ×’×“×•×œ ×™×•×ª×¨, × ×™×ª×Ÿ ×œ×”×©×ª××© ×‘-K ×’×“×•×œ ×™×•×ª×¨.
   
2. **×¨××ª ×”×¨×¢×© ×‘× ×ª×•× ×™×**: 
   - ×œ× ×ª×•× ×™× ×¢× ××¢×˜ ×¨×¢×©: K ×§×˜×Ÿ ×™×•×ª×¨ (1-5)
   - ×œ× ×ª×•× ×™× ×¢× ×”×¨×‘×” ×¨×¢×©: K ×’×“×•×œ ×™×•×ª×¨ (×œ×”×¤×—×™×ª ××ª ×”×©×¤×¢×ª ×”×¨×¢×©)

3. **××•×¨×›×‘×•×ª ×”×’×‘×•×œ×•×ª ×‘×™×Ÿ ×”××—×œ×§×•×ª**:
   - ×’×‘×•×œ×•×ª ×¤×©×•×˜×™×: K ×’×“×•×œ ×™×•×ª×¨
   - ×’×‘×•×œ×•×ª ××•×¨×›×‘×™×: K ×§×˜×Ÿ ×™×•×ª×¨

4. **×›×œ×œ ××¦×‘×¢**: ×œ×¢×ª×™× ×§×¨×•×‘×•×ª ××•××œ×¥ ×œ×”×ª×—×™×œ ×¢× $K = \sqrt{n}$ ×›××©×¨ n ×”×•× ××¡×¤×¨ ×”×“×•×’×××•×ª ×‘××“×’× ×”××™××•×Ÿ.

5. **×¢×¨×›×™× ××™-×–×•×’×™×™×**: ×¢×‘×•×¨ ×‘×¢×™×•×ª ×¡×™×•×•×’ ×‘×™× ××¨×™, ×›×“××™ ×œ×‘×—×•×¨ ×¢×¨×›×™ K ××™-×–×•×’×™×™× ×›×“×™ ×œ×× ×•×¢ ×ª×™×§×•.

## ×™×™×©×•× ××¢×©×™ - ×©×™××•×© ×‘×›×œ ×”×©×™×˜×•×ª

× ×¡×›× ××ª ×›×œ ××” ×©×œ××“× ×• ×‘×“×•×’××” ××¢×©×™×ª ××§×™×¤×”:

```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

# ×˜×¢×™× ×ª × ×ª×•× ×™× (×œ×“×•×’××” × ×©×ª××© ×‘-Iris dataset)
from sklearn.datasets import load_iris
iris = load_iris()
X = iris.data
y = iris.target
feature_names = iris.feature_names
target_names = iris.target_names

# ×ª×§× ×•×Ÿ ×”× ×ª×•× ×™×
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# ×—×œ×•×§×” ×œ××™××•×Ÿ ×•×‘×“×™×§×”
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42, stratify=y)

# ×—×œ×§ 1: ×‘×—×™×¨×ª K ××•×¤×˜×™××œ×™ 
k_range = range(1, 30, 2)  # ×¢×¨×›×™ K ××™-×–×•×’×™×™× ×¢×“ 30

# ×©×™×˜×” 1: Elbow Method
test_scores = []
for k in k_range:
    knn = KNeighborsClassifier(n_neighbors=k)
    knn.fit(X_train, y_train)
    test_scores.append(accuracy_score(y_test, knn.predict(X_test)))

# ×©×™×˜×” 2: Cross-Validation
cv_scores = []
for k in k_range:
    knn = KNeighborsClassifier(n_neighbors=k)
    scores = cross_val_score(knn, X_scaled, y, cv=10, scoring='accuracy')
    cv_scores.append(scores.mean())

# ×©×™×˜×” 3: GridSearchCV
param_grid = {'n_neighbors': list(k_range)}
grid_search = GridSearchCV(KNeighborsClassifier(), param_grid, cv=10)
grid_search.fit(X_scaled, y)

# ×”×¦×’×ª ×ª×•×¦××•×ª ×‘×—×™×¨×ª K
plt.figure(figsize=(12, 6))
plt.plot(k_range, test_scores, marker='o', label='Test Accuracy')
plt.plot(k_range, cv_scores, marker='s', label='CV Accuracy')
plt.axvline(x=k_range[np.argmax(test_scores)], color='r', linestyle='--', 
            label=f'Best K (Test): {k_range[np.argmax(test_scores)]}')
plt.axvline(x=k_range[np.argmax(cv_scores)], color='g', linestyle='--', 
            label=f'Best K (CV): {k_range[np.argmax(cv_scores)]}')
plt.axvline(x=grid_search.best_params_['n_neighbors'], color='m', linestyle='--', 
            label=f"Best K (GridSearch): {grid_search.best_params_['n_neighbors']}")
plt.title('Finding Optimal K Value')
plt.xlabel('K Value')
plt.ylabel('Accuracy')
plt.legend()
plt.grid(True)
plt.show()

# ×—×œ×§ 2: ×˜×™×¤×•×œ ×‘×ª×™×§×• - ×©×™××•×© ×‘××©×§×•×œ×•×ª ××¨×—×§
best_k = grid_search.best_params_['n_neighbors']
knn_uniform = KNeighborsClassifier(n_neighbors=best_k, weights='uniform')
knn_distance = KNeighborsClassifier(n_neighbors=best_k, weights='distance')

# × ×“×’×™× ××ª ×”×”×‘×“×œ ×‘×“×™×•×§ ×‘×™×Ÿ ×©× ×™ ×”××•×“×œ×™×
knn_uniform.fit(X_train, y_train)
knn_distance.fit(X_train, y_train)

y_pred_uniform = knn_uniform.predict(X_test)
y_pred_distance = knn_distance.predict(X_test)

print("Uniform Weights Accuracy:", accuracy_score(y_test, y_pred_uniform))
print("Distance Weights Accuracy:", accuracy_score(y_test, y_pred_distance))

# ×—×œ×§ 3: ××“×“×™ ×”×¢×¨×›×” ××¤×•×¨×˜×™×
print("\nClassification Report (Distance Weights):")
print(classification_report(y_test, y_pred_distance, target_names=target_names))

# ×”×¦×’×ª ××˜×¨×™×¦×ª ×”×‘×œ×‘×•×œ
plt.figure(figsize=(8, 6))
cm = confusion_matrix(y_test, y_pred_distance)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
            xticklabels=target_names, 
            yticklabels=target_names)
plt.title('Confusion Matrix')
plt.ylabel('Actual')
plt.xlabel('Predicted')
plt.show()

# ×—×œ×§ 4: ×•×™×–×•××œ×™×–×¦×™×” ×©×œ ×”×—×œ×˜×•×ª ×”×¡×™×•×•×’
# ×¨×§ ×¢× ×©× ×™ ×××“×™× ×œ×¦×•×¨×š ×”×•×™×–×•××œ×™×–×¦×™×” (2 ×××¤×™×™× ×™× ×¨××©×•× ×™×)
X_2d = X_scaled[:, :2]
y_2d = y

# ×—×œ×•×§×” ×œ××™××•×Ÿ ×•×‘×“×™×§×”
X_2d_train, X_2d_test, y_2d_train, y_2d_test = train_test_split(X_2d, y_2d, test_size=0.3, random_state=42)

# ××™××•×Ÿ ×”××•×“×œ
knn_2d = KNeighborsClassifier(n_neighbors=best_k, weights='distance')
knn_2d.fit(X_2d_train, y_2d_train)

# ×™×¦×™×¨×ª ×¨×©×ª ×œ×•×™×–×•××œ×™×–×¦×™×”
h = 0.02  # ×’×•×“×œ ×¦×¢×“ ×‘×’×¨×™×“
x_min, x_max = X_2d[:, 0].min() - 1, X_2d[:, 0].max() + 1
y_min, y_max = X_2d[:, 1].min() - 1, X_2d[:, 1].max() + 1
xx, yy = np.meshgrid(np.arange(x_min, x_max, h),
                     np.arange(y_min, y_max, h))

# ×—×™×–×•×™ ×¢×‘×•×¨ ×›×œ × ×§×•×“×” ×‘×¨×©×ª
Z = knn_2d.predict(np.c_[xx.ravel(), yy.ravel()])
Z = Z.reshape(xx.shape)

# ×”×¦×’×ª ××–×•×¨×™ ×”×”×—×œ×˜×”
plt.figure(figsize=(10, 8))
plt.contourf(xx, yy, Z, alpha=0.3, cmap=plt.cm.coolwarm)

# ×”×¦×’×ª × ×§×•×“×•×ª ×”××™××•×Ÿ
scatter = plt.scatter(X_2d[:, 0], X_2d[:, 1], c=y, edgecolors='k', 
                    s=80, cmap=plt.cm.coolwarm)

plt.title(f'KNN Decision Boundaries with K={best_k}')
plt.xlabel(feature_names[0])
plt.ylabel(feature_names[1])
plt.legend(*scatter.legend_elements(), title="Classes", loc="upper right")
plt.show()

# ×—×œ×§ 5: ×”×“×’××ª ×˜×™×¤×•×œ ×‘×ª×™×§×• - ××¦×™××ª × ×§×•×“×•×ª ×¢× ×ª×™×§×• ×¤×•×˜× ×¦×™××œ×™
def find_potential_ties(X, y, k):
    """××¦×™××ª × ×§×•×“×•×ª ×¢× ×ª×™×§×• ×¤×•×˜× ×¦×™××œ×™ - ×›×œ×•××¨ × ×§×•×“×•×ª ×©×× ×”×™×™× ×• ××¡×•×•×’×™× ××•×ª×Ÿ ×¢× K ×©×›× ×™×
    ×”×™×” × ×•×¦×¨ ×ª×™×§×• ×‘×™×Ÿ ×©×ª×™ ×§×˜×’×•×¨×™×•×ª ××• ×™×•×ª×¨"""
    potential_ties = []
    
    for i, x in enumerate(X):
        # ×—×™×©×•×‘ ××¨×—×§×™× ××›×œ ×”× ×§×•×“×•×ª ×”××—×¨×•×ª
        distances = []
        for j, other_x in enumerate(X):
            if i != j:  # ×œ× ×›×•×œ×œ ××ª ×”× ×§×•×“×” ×¢×¦××”
                dist = np.sqrt(np.sum((x - other_x) ** 2))
                distances.append((dist, j))
        
        # ××™×•×Ÿ ×”××¨×—×§×™× ×•×‘×—×™×¨×ª K ×”×§×¨×•×‘×™× ×‘×™×•×ª×¨
        distances.sort()
        k_nearest = distances[:k]
        
        # ×¡×¤×™×¨×ª ×”×§×˜×’×•×¨×™×•×ª
        class_counts = {}
        for _, idx in k_nearest:
            label = y[idx]
            if label in class_counts:
                class_counts[label] += 1
            else:
                class_counts[label] = 1
        
        # ×‘×“×™×§×” ×× ×™×© ×ª×™×§×• (×©×ª×™ ×§×˜×’×•×¨×™×•×ª ××• ×™×•×ª×¨ ×¢× ××•×ª×• ××¡×¤×¨ ×©×›× ×™×)
        values = list(class_counts.values())
        if len(values) > 1 and values.count(max(values)) > 1:
            potential_ties.append((i, class_counts))
    
    return potential_ties

# ××¦×™××ª × ×§×•×“×•×ª ×¢× ×ª×™×§×• ×¤×•×˜× ×¦×™××œ×™ ×¢×œ ×§×‘×•×¦×ª ×”××™××•×Ÿ
k_to_check = 4  # K ×–×•×’×™, ×™×•×ª×¨ ×¡×™×›×•×™ ×œ×ª×™×§×•
potential_ties = find_potential_ties(X_2d, y_2d, k_to_check)

if potential_ties:
    print(f"\n××¦×× ×• {len(potential_ties)} × ×§×•×“×•×ª ×¢× ×ª×™×§×• ×¤×•×˜× ×¦×™××œ×™ ×›××©×¨ K={k_to_check}")
    
    # ××“×’×™× ××ª 3 ×”× ×§×•×“×•×ª ×”×¨××©×•× ×•×ª ×¢× ×ª×™×§×•
    for i, (idx, counts) in enumerate(potential_ties[:3]):
        print(f"× ×§×•×“×” {idx}: {dict(counts)}")
        
        # ×•×™×–×•××œ×™×–×¦×™×” ×©×œ × ×§×•×“×” ×¢× ×ª×™×§×•
        plt.figure(figsize=(8, 6))
        
        # ×”×¦×’×ª ×›×œ ×”× ×§×•×“×•×ª
        plt.scatter(X_2d[:, 0], X_2d[:, 1], c=y_2d, cmap=plt.cm.coolwarm, alpha=0.3)
        
        # ×”×“×’×©×ª ×”× ×§×•×“×” ×¢× ×”×ª×™×§×•
        plt.scatter(X_2d[idx, 0], X_2d[idx, 1], color='black', s=100, marker='*')
        
        # ××¦×™××ª ×”×©×›× ×™× ×”×§×¨×•×‘×™×
        distances = []
        for j, other_x in enumerate(X_2d):
            if idx != j:
                dist = np.sqrt(np.sum((X_2d[idx] - other_x) ** 2))
                distances.append((dist, j))
        
        distances.sort()
        k_nearest = distances[:k_to_check]
        
        # ×”×“×’×©×ª ×”×©×›× ×™× ×”×§×¨×•×‘×™× ×‘×™×•×ª×¨
        for dist, neighbor_idx in k_nearest:
            plt.scatter(X_2d[neighbor_idx, 0], X_2d[neighbor_idx, 1], 
                      color='red', s=80, alpha=0.6, edgecolors='k')
            
            # ×¦×™×•×¨ ×§×• ××”× ×§×•×“×” ×œ×©×›×Ÿ
            plt.plot([X_2d[idx, 0], X_2d[neighbor_idx, 0]], 
                   [X_2d[idx, 1], X_2d[neighbor_idx, 1]], 'k--', alpha=0.3)
        
        # ×”×•×¡×¤×ª ××¢×’×œ ×”××“×’×™×© ××ª ××–×•×¨ ×”×©×›× ×™× ×”×§×¨×•×‘×™×
        max_dist = k_nearest[-1][0]
        circle = plt.Circle((X_2d[idx, 0], X_2d[idx, 1]), max_dist, 
                          fill=False, color='blue', linestyle='-')
        plt.gca().add_patch(circle)
        
        plt.title(f'Tie Example {i+1}: Point {idx} with K={k_to_check}')
        plt.xlabel(feature_names[0])
        plt.ylabel(feature_names[1])
        plt.show()
else:
    print(f"×œ× × ××¦××• × ×§×•×“×•×ª ×¢× ×ª×™×§×• ×¤×•×˜× ×¦×™××œ×™ ×›××©×¨ K={k_to_check}")
```

## ×¡×™×›×•×

×‘×—×™×¨×ª ×¢×¨×š K ×”××•×¤×˜×™××œ×™ ×”×™× ××¤×ª×— ×œ×”×¦×œ×—×ª ××œ×’×•×¨×™×ª× KNN:

1. **×©×™×˜×•×ª ××•××œ×¦×•×ª ×œ×‘×—×™×¨×ª K**:
   - ×¢×‘×•×¨ ××“×’××™× ×§×˜× ×™×: ××™××•×ª ×¦×•×œ×‘ (cross-validation)
   - ×¢×‘×•×¨ ××“×’××™× ×’×“×•×œ×™×: ×©×™×˜×ª Elbow ××• GridSearchCV
   - ×©×™××•×© ×‘-K ××™-×–×•×’×™ ×œ×× ×™×¢×ª ×ª×™×§×• ×‘×‘×¢×™×•×ª ×‘×™× ××¨×™×•×ª

2. **×˜×™×¤×•×œ ×‘××§×¨×™ ×ª×™×§×•**:
   - ×©×™××•×© ×‘××©×§×•×œ×•×ª ××¨×—×§ (`weights='distance'`)
   - ×‘×—×™×¨×ª K ××™-×–×•×’×™
   - ×”×¤×—×ª×ª K ××• ×”×’×“×œ×ª×• ×‘××§×¨×” ×”×¦×•×¨×š

3. **×˜×™×¤×™× ×œ×©×™×¤×•×¨ ×‘×™×¦×•×¢×™ KNN**:
   - ×ª×§× ×•×Ÿ × ×ª×•× ×™× ×”×•× ×§×¨×™×˜×™!
   - ×¡×™×œ×•×§ ×××¤×™×™× ×™× ×œ× ×¨×œ×•×•× ×˜×™×™× (feature selection)
   - ×©×§×™×œ×ª ×©×™××•×© ×‘×©×™×˜×•×ª ×”×¤×—×ª×ª ×××“×™× (×›××• PCA)
   - ×”×ª×××ª ××“×“ ××¨×—×§ ×œ×¡×•×’ ×”× ×ª×•× ×™× (×× ×”×˜×Ÿ, ×™×•×§×œ×™×“×™, ××™× ×§×•×‘×¡×§×™)

## ×ª×¨×’×™×œ

**×ª×¨×’×™×œ**: ×—×‘×¨×ª ××©×¨××™ ××©×ª××©×ª ×‘××œ×’×•×¨×™×ª× KNN ×œ× ×™×‘×•×™ ×¡×™×›×•×Ÿ ×”×œ×•×•××•×ª. ×”× ×ª×•× ×™× ×›×•×œ×œ×™× 100 ×œ×§×•×—×•×ª. ×‘× ×™×¡×™×•×Ÿ ×œ×§×‘×•×¢ ××ª ×¢×¨×š K ×”××•×¤×˜×™××œ×™, ×”×ª×§×‘×œ×• ×”×ª×•×¦××•×ª ×”×‘××•×ª:

| K | ×“×™×•×§ (Accuracy) | Precision | Recall | F1 Score |
|---|----------------|-----------|--------|----------|
| 1 | 0.82           | 0.75      | 0
