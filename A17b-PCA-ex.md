# ğŸ“‰ ×ª×”×œ×™×š ×¦××¦×•× ××™××“×™× ×¢× PCA

### 1. ×˜×¢×™× ×ª ×”× ×ª×•× ×™×
×™×© ×œ× ×• ×§×•×‘×¥ × ×ª×•× ×™× ×¢× 20 ×¤×™×¦'×¨×™× ×©×•× ×™×. × ×¨×¦×” ×œ×‘×“×•×§ ×× ××¤×©×¨ ×œ×¦××¦× ××ª ×›××•×ª ×”×¤×™×¦'×¨×™× ××‘×œ×™ ×œ××‘×“ ××™×“×¢ ××”×•×ª×™

<img src="pca4.jpg" style="width: 80%" />

### 2. ×¤×™×¦'×¨ ×¡×§×™×™×œ×™× ×’

× ×©×ª××© ×‘- StandardScaler 

### 3. ×”×¤×¢×œ×ª PCA ×¢× 2 ×¨×›×™×‘×™×
× ×‘×¦×¢ × ×™×ª×•×— PCA ×¢×œ ×”×“××˜×” ×ª×•×š ×©××™×¨×” ×¢×œ 2 ×¨×›×™×‘×™× ×‘×œ×‘×“
×”××˜×¨×” ×”×™× ×œ×‘×“×•×§ ×”×× ×©× ×™ ×”×¨×›×™×‘×™× ××¦×œ×™×—×™× ×œ×©××¨ ×—×œ×§ ××©××¢×•×ª×™ ××”×©×•× ×•×ª (×”××™×“×¢) ×©×œ ×”×“××˜×”

× ×¦×™×’ ××ª ×”× ×ª×•× ×™× ×‘×¢×–×¨×ª ×ª×¨×©×™× ×¤×™×–×•×¨ (Scatter Plot) ×›×“×™ ×œ×”×‘×™×Ÿ ××™×š ×”× ××ª×¤×œ×’×™× ×‘××¨×—×‘

<img src="pca2.png" style="width: 80%" />

### 4. ××“×™×“×ª ×©×•× ×•×ª ××•×¡×‘×¨×ª (Explained Variance)
× ×‘×“×•×§ ×›××” ××”×©×•× ×•×ª ×”×›×•×œ×œ×ª ×‘×“××˜×” × ×©××¨×ª ×¢×œ ×™×“×™ ×©× ×™ ×”×¨×›×™×‘×™×
×× ×”×©×•× ×•×ª ×’×‘×•×”×” (×œ××©×œ ××¢×œ 80%) â€” ×™×™×ª×›×Ÿ ×©××™×Ÿ ×¦×•×¨×š ×‘×™×•×ª×¨ ×-2 ×¨×›×™×‘×™×

### 5. ×”×¢×œ××ª ×›××•×ª ×”×¨×›×™×‘×™×
× ×¨×™×¥ ××ª PCA ×©×•×‘, ×”×¤×¢× ×¢× ×›××•×ª ××©×ª× ×” ×©×œ ×¨×›×™×‘×™× (3, 4, ..., 20)  
×‘×›×œ ×¤×¢× × ××“×•×“ ××ª **×”×©×•× ×•×ª ×”××¦×˜×‘×¨×ª** ×©× ×©××¨×ª

### 6. ×©×¨×˜×•×˜ ×©×•× ×•×ª ××•×¡×‘×¨×ª ××¦×˜×‘×¨×ª
× ×¦×™×’ ×’×¨×£ ×©×œ "×›××•×ª ×¨×›×™×‘×™×" ××•×œ "×©×•× ×•×ª ××•×¡×‘×¨×ª ××¦×˜×‘×¨×ª" ×›×“×™ ×œ×–×”×•×ª ××ª × ×§×•×“×ª ×”××¤× ×” (elbow point)  
×›×š × ×•×›×œ ×œ×‘×—×•×¨ ××ª ××¡×¤×¨ ×”×¨×›×™×‘×™× ×”××•×¤×˜×™××œ×™ ×©××¡×‘×™×¨ ××¡×¤×™×§ ××”××™×“×¢ ×ª×•×š ×©××™×¨×” ×¢×œ ×¤×©×˜×•×ª

<img src="pca3.png" style="width: 80%" />

---

## ×”×§×•×“

```python
# Step 1: Load the data
import pandas as pd
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt

df = pd.read_csv('tumor_data_features.csv')

# Step 2: Feature scaling
scaler = StandardScaler()
scaled_data = scaler.fit_transform(df)

# Step 3: PCA with 2 components
pca = PCA(n_components=2)
pca_result = pca.fit_transform(scaled_data)

# Step 4: Scatter plot of the PCA result
plt.scatter(pca_result[:, 0], pca_result[:, 1])
plt.title('PCA - 2 Principal Components')
plt.xlabel('PC1')
plt.ylabel('PC2')
plt.grid(True)
plt.show()

# Step 5: View the PCA components
print("PCA Components:")
print(pca.components_)

# Step 6: View the explained variance ratio
print("Explained Variance Ratio:")
print(pca.explained_variance_ratio_)

# Step 7: Calculate explained variance for different number of components
explained = []
for i in range(1, 31):  # assuming there are 30 original features
    pca = PCA(n_components=i)
    pca.fit(scaled_data)
    explained.append(sum(pca.explained_variance_ratio_))

# Step 8: Line plot of explained variance vs number of components
plt.plot(range(1, 31), explained, marker='o')
plt.title('Explained Variance vs Number of Components')
plt.xlabel('Number of Principal Components')
plt.ylabel('Cumulative Explained Variance')
plt.grid(True)
plt.show()

```