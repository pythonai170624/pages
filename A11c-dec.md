# השוואה בין Gini Impurity ל-Entropy

## נוסחאות:

### 1. Gini Impurity:
\[
Gini = 1 - \sum_{i=1}^{n} p_i^2
\]

כאשר:
- \(p_i\) הוא ההסתברות של כל קטגוריה \(i\) בקבוצה.

---

### 2. Entropy:
\[
Entropy = - \sum_{i=1}^{n} p_i \cdot \log_2(p_i)
\]

כאשר:
- \(p_i\) הוא ההסתברות של כל קטגוריה \(i\) בקבוצה.

---

## דוגמה מספרית:

נניח שיש לנו קבוצה עם שתי קטגוריות:
- חיובי (Positive) עם הסתברות \(p_1 = 0.7\)
- שלילי (Negative) עם הסתברות \(p_2 = 0.3\)

### חישוב Gini:
\[
Gini = 1 - (0.7^2 + 0.3^2) = 1 - (0.49 + 0.09) = 0.42
\]

### חישוב Entropy:
\[
Entropy = - (0.7 \cdot \log_2(0.7) + 0.3 \cdot \log_2(0.3)) \\
Entropy = - (0.7 \cdot -0.5146 + 0.3 \cdot -1.737) \\
Entropy \approx - (-0.3602 - 0.5211) = 0.8813
\]

---

## מתי להשתמש?

| מאפיין            | Gini Impurity           | Entropy                  |
|-------------------|-------------------------|--------------------------|
| חישוביות          | מהיר יותר (ללא לוגריתם) | איטי יותר (יש לוגריתם)   |
| רגישות            | פחות רגיש להבדלים קטנים | יותר רגיש להבדלים קטנים  |
| מתי לבחור         | כשחשובה מהירות          | כשחשובה דיוק/מידע         |
| שימוש נפוץ        | Decision Tree (CART)    | Decision Tree (ID3, C4.5)|

**המלצה כללית:**
- אם יש לך הרבה נתונים או אתה צריך חישוב מהיר → **Gini**  
- אם אתה רוצה להיות רגיש יותר לאי-ודאות → **Entropy**

---

## גרפים (במילים 😅):

- **Gini** מקסימלי כשההסתברויות שוות (0.5, 0.5).
- **Entropy** גם מקסימלי כשההסתברויות שוות, אבל הערך שלו גדול יותר (1 לעומת 0.5 ב-Gini לשני מחלקות).

