# Topic Modeling 

## 🧠 מה זה Topic Modeling?

ה- Topic Modeling הוא שיטה ב־NLP שמטרתה **לגלות נושאים סמויים** מתוך טקסטים לא מתויגים  
(כלומר: Unsupervised Learning).  
זהו מודל סטטיסטי שמנסה להבין על מה מדברים בטקסט, מבלי שהתווינו לו תגיות מראש

## 📌 מה זה Topic?

ה- "Topic" (נושא) הוא אוסף מילים שמופיעות הרבה יחד ומרמזות על נושא משותף  
לדוגמה: נושא על פירות עשוי לכלול את המילים "apple", "banana", "orange"

## 🛠️ למה משתמשים בזה?

- **המלצות תוכן** – התאמת מאמרים דומים לפי נושאים
- **קיבוץ מסמכים** – על בסיס דמיון רעיוני
- **ניתוח מגמות** – מעקב אחרי שינויי נושאים לאורך זמן
- **שיפור מנועי חיפוש** – על ידי הבנת נושא המסמך

## 🔑 שלבים עיקריים ב־Topic Modeling:

1. **עיבוד מקדים של הטקסט**  
   כולל טוקניזציה, הסרת stop words, סטמינג / למטיזציה, וקטוריזציה (TF-IDF / Count)

2. **בחירת מספר נושאים (k)**  
   כמו ב־Clustering – אנחנו קובעים כמה נושאים המודל ינסה למצוא

3. **אימון המודל**  
   משתמשים באלגוריתמים כמו:
   - LDA – Latent Dirichlet Allocation
   - NMF – Non-Negative Matrix Factorization

4. **פרשנות והבנה של הנושאים**  
   המודל מחזיר:
   - עבור כל נושא → רשימת מילים אופייניות
   - עבור כל טקסט → הסתברות לכל נושא

## 📘 דוגמה: LDA Model

LDA (Latent Dirichlet Allocation) הוא המודל הנפוץ ביותר  
הוא מניח שכל טקסט הוא שילוב של כמה נושאים, וכל נושא הוא שילוב של כמה מילים

לדוגמה:
- נושא 1 = {"computer", "keyboard", "office"} → נושא: טכנולוגיה
- נושא 2 = {"dog", "cat", "animal"} → נושא: חיות

המודל מחזיר:
- לכל מסמך → הסתברויות שייך לכל נושא
- לכל נושא → הסתברויות של כל מילה באוצר המילים

## 📊 ההבדל בין Topic Modeling לבין Clustering רגיל

| תכונה                      | Topic Modeling (LDA)           | Clustering רגיל (KMeans למשל) |
|----------------------------|--------------------------------|-------------------------------|
| מספר תוויות לכל מסמך       | כמה נושאים עם הסתברויות       | רק קלאסטר אחד                |
| למידה מונחית או לא?         | לא מונחית (Unsupervised)        | לרוב לא מונחית               |
| משקל לכל תכונה              | לפי הסתברות מילה לנושא         | לפי מיקום במרחב              |

## 🧪 בפועל:

> נריץ LDA על טקסטים ונקבל:
> - עבור כל מסמך: לאיזה נושאים הוא שייך (ואחוז שייכות)
> - עבור כל נושא: אילו מילים מייצגות אותו הכי חזק

---

