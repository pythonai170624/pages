# NLP FETAURES

## ××”×• ×§×•×¨×¤×•×¡ (Corpus)

×§×•×¨×¤×•×¡ ×”×•× ××•×¡×£ ×’×“×•×œ ×©×œ ×˜×§×¡×˜×™× ×”××©××© ×œ×œ×™××•×“ ×•× ×™×ª×•×— ×©×¤×” ×˜×‘×¢×™×ª. ×–×” ×™×›×•×œ ×œ×”×™×•×ª ×˜×§×¡×˜×™× ×¡×¤×¨×•×ª×™×™×, ×—×“×©×•×ª, ×ª××œ×•×œ×™× ×©×œ ×“×™×‘×•×¨, ××ª×¨×™ ××™× ×˜×¨× ×˜ ×•×¢×•×“

×‘×§×•× ×˜×§×¡×˜ ×©×œ NLP, ×§×•×¨×¤×•×¡ ××©××© ×œ××™××•×Ÿ, ×‘×“×™×§×” ×•×”×¢×¨×›×” ×©×œ ××•×“×œ×™× â€“ ×œ×“×•×’××”, ××•×“×œ×™× ×©×œ ×—×œ×§×™ ×“×™×‘×¨ (POS) ××• ×–×™×”×•×™ ×™×©×•×™×•×ª (NER)

#### ×¡×•×’×™ ×§×•×¨×¤×•×¡×™×:

* **×§×•×¨×¤×•×¡ ×œ× ××¡×•××Ÿ** (raw corpus): ×˜×§×¡×˜ ×¨×’×™×œ ×œ×œ× ×ª×™×•×’
* **×§×•×¨×¤×•×¡ ××¡×•××Ÿ** (annotated corpus): ×›×•×œ×œ ××™×“×¢ × ×•×¡×£ ×›××• ×—×œ×§×™ ×“×™×‘×¨, ×ª×—×‘×™×¨, ×™×©×•×™×•×ª ×•×›×•'

ğŸ“Œ ×”- SpaCy ××•×× ×” ×¢×œ ×§×•×¨×¤×•×¡×™× ××¡×•×× ×™×, ××” ×©×××¤×©×¨ ×œ×” ×œ×”×‘×™×Ÿ ×”×§×©×¨×™× ×•×œ×–×”×•×ª ××‘× ×™× ×œ×©×•× ×™×™× ××•×¨×›×‘×™×

**×“×•×’×× 1**

```python
import spacy
nlp = spacy.load('en_core_web_sm')
doc = nlp("The quick brown fox jumped over the lazy dog's back.")

print(doc[4].text, doc[4].pos_, doc[4].tag_, spacy.explain(doc[4].tag_))
```

Output:
```
jumped VERB VBD verb, past tense
```

SpaCy decided that the token jumped is a verb with the VBD tag, meaning it's a verb in past tense

**×“×•×’×× 2**

```python
doc1 = nlp(u'I read books on NLP.')
doc2 = nlp(u'I read a book on NLP.')

print(f'{doc1[1].text:10} {doc1[1].pos_:8} {doc1[1].tag_:6} {spacy.explain(doc1[1].tag_)}')
print()
print(f'{doc2[1].text:10} {doc2[1].pos_:8} {doc2[1].tag_:6} {spacy.explain(doc2[1].tag_)}')
```

Output:
```
read       VERB     VBP    verb, non-3rd person singular present

read       VERB     VBD    verb, past tense
```

ğŸ“Œ SpaCy is smart enough to understand from the textual context that the first read token is in present tense, while the second read is in past tense

## Named Entity Recognition (NER)

×”- NER ×”×•× ×ª×”×œ×™×š ×©×‘×• ××–×”×™× ×™×©×•×™×•×ª ×‘×©× ×‘×˜×§×¡×˜ (×›××• ×©××•×ª ×©×œ ×× ×©×™×, ××§×•××•×ª, ×—×‘×¨×•×ª, ×¡×›×•××™×, ×ª××¨×™×›×™× ×•×›×•')

#### â€¢ **Named Entities**  
×‘× ×™×™×ª ×¨×©×™××” ×©×œ ×™×©×•×™×•×ª ×‘×©× ××ª×•×š ×”×˜×§×¡×˜, ×›×©×”××¤×ª×— ×”×•× ×¡×•×’ ×”×™×©×•×ª ×•×”×¢×¨×›×™× ×”× ×”××•×¤×¢×™× ×©×–×•×”×•  
×œ×“×•×’××”:
- **Persons (PER)** â€“ ×©××•×ª ×©×œ ×× ×©×™× ×›××•: `"Albert Einstein"`, `"Marie Curie"`
- **Locations (LOC)** â€“ ××§×•××•×ª ×’×™××•×’×¨×¤×™×™× ×›××•: `"Paris"`, `"Mount Everest"`

#### â€¢ **Recognition**  
×–×™×”×•×™ ×‘×¤×•×¢×œ ×©×œ ×”××™×œ×™× ××• ×”×‘×™×˜×•×™×™× ×‘×˜×§×¡×˜ ×©××™×™×¦×’×™× ×™×©×•×™×•×ª ×‘×©×  
×œ×“×•×’××”: ×‘××©×¤×˜ `"Barack Obama visited Paris"` â€“ × ×–×”×” ××ª `"Barack Obama"` ×•××ª `"Paris"` ×›×™×©×•×™×•×ª

#### â€¢ **Classification**  
×©×™×•×š ×›×œ ×™×©×•×ª ×©× ××¦××” ×œ×§×˜×’×•×¨×™×” ××ª××™××” (×›××• `PERSON`, `LOCATION`, `ORG`, `DATE` ×•×›×•')


#### ×©×œ×‘×™×:

1. **Tokenization** â€“ ×¤×™×¦×•×œ ×”×˜×§×¡×˜ ×œ××™×œ×™×
2. **Feature Extraction** â€“ ×”×¤×§×ª ×××¤×™×™× ×™× ×›××• ×¦×•×¨×ª ××™×œ×”, ××•×ª×™×•×ª ×’×“×•×œ×•×ª, ×¡×™×•××•×ª
3. **Model Training** â€“ ××™××•×Ÿ ××•×“×œ ×¢×œ ×˜×§×¡×˜×™× ××¡×•×× ×™× ××¨××©
4. **Prediction** â€“ ×–×™×”×•×™ ×™×©×•×™×•×ª ×‘×˜×§×¡×˜ ×—×“×©

×•× ×‘×¦×¢ ×¢×œ×™×• ×ª×”×œ×™×š ×–×™×”×•×™ ×™×©×•×™×•×ª ×‘×©× (NER). ×”×ª×”×œ×™×š ×›×•×œ×œ ××¨×‘×¢×” ×©×œ×‘×™× ×¢×™×§×¨×™×™×:

`Barack Obama was born on August 4, 1961, in Honolulu, Hawaii.`

#### 1. **Tokenization** â€“ ×¤×™×¦×•×œ ×”×˜×§×¡×˜ ×œ××™×œ×™× (×˜×•×§× ×™×)  
SpaCy ××¤×¨×§×ª ××ª ×”××©×¤×˜ ×œ××™×œ×™× ×•×ª×•×•×™ ×¤×™×¡×•×§ â€“ ×›××• `"Barack"`, `"Obama"`, `"August"`, `"4"`, `"1961"`, `","`, `"Hawaii"` ×•×›×•'

#### 2. **Feature Extraction** â€“ ×”×¤×§×ª ×××¤×™×™× ×™× ××”×˜×•×§× ×™×  
×œ×›×œ ××™×œ×” ××—×•×œ×¦×™× ×××¤×™×™× ×™× ×›××•:  
- ×”×× ×”××•×ª ×”×¨××©×•× ×” ×’×“×•×œ×”? (Barack)  
- ×”×× ×–×• ××™×œ×” ××¡×¤×¨×™×ª ××• ×ª××¨×™×š? (4, 1961)  
- ×”×× ×”×™× ×××•×§××ª ××—×¨×™ ××™×œ×ª ××¤×ª×— ×›××• "born on"?  

×××¤×™×™× ×™× ××œ×• ×¢×•×–×¨×™× ×œ××•×“×œ ×œ×”×‘×™×Ÿ ××™×œ×• ××™×œ×™× ×¢×©×•×™×•×ª ×œ×”×™×•×ª ×™×©×•×™×•×ª

#### 3. **Model Training** â€“ (×›×‘×¨ ×‘×•×¦×¢ ××¨××© ×¢×œ ×™×“×™ spaCy)  
×”××•×“×œ ×©××•××Ÿ ×¢×œ ×§×•×¨×¤×•×¡ ×’×“×•×œ ×™×•×“×¢ ×œ×–×”×•×ª ××‘× ×™× ×©×œ ×©××•×ª ×¤×¨×˜×™×™×, ×ª××¨×™×›×™×, ×¢×¨×™× ×•×¢×•×“

#### 4. **Prediction** â€“ ×—×™×–×•×™ ×”×™×©×•×™×•×ª ×‘×˜×§×¡×˜  
×”××•×“×œ ××–×”×” ××ª ×”×™×©×•×™×•×ª ×”×‘××•×ª:



```python
doc = nlp("Barack Obama was born on August 4, 1961, in Honolulu, Hawaii.")
for ent in doc.ents:
    print(ent.text, ent.label_, spacy.explain(ent.label_))
```

Output:
```
Barack Obama PERSON People, including fictional
August 4, 1961 DATE Absolute or relative dates or periods
Honolulu GPE Countries, cities, states
Hawaii GPE Countries, cities, states
```

ğŸ“Œ ×”- SpaCy ××—×–×™×¨ ×™×©×•×™×•×ª ×¢× label ×›××• `PERSON`, `DATE`, `GPE` ×•×××¤×©×¨ ×œ×”×¡×‘×™×¨ ×›×œ label ×‘×××¦×¢×•×ª `spacy.explain`

---

### NER Customization â€“ ×”×ª×××” ××™×©×™×ª ×©×œ ×™×©×•×™×•×ª

× ×™×ª×Ÿ ×œ×”×•×¡×™×£ ×™×©×•×™×•×ª ×©×œ× ×–×•×”×• ×¢"×™ SpaCy ×›×‘×¨×™×¨×ª ××—×“×œ. ×œ×“×•×’××”: ×œ×”×’×“×™×¨ ××ª 'Tesla' ×›××¨×’×•×Ÿ (`ORG`), ×× SpaCy ×œ× ××–×”×” ×–××ª ×œ×‘×“.

```python
from spacy.tokens import Span
ORG = doc.vocab.strings["ORG"]
new_ent = Span(doc, start=0, end=1, label=ORG)
doc.ents = list(doc.ents) + [new_ent]
```

××¤×©×¨ ×’× ×œ×”×©×ª××© ×‘Ö¾PhraseMatcher ×›×“×™ ×œ×–×”×•×ª ×ª×‘× ×™×•×ª ×§×‘×•×¢×•×ª ×›××•:

* `dashboard-website`
* `dashboard website`
  ×•×œ×”×’×“×™×¨ ××•×ª×Ÿ ×›Ö¾`PRODUCT`

×œ××—×¨ ×”×–×™×”×•×™ ×¢× phrase matcher â€“ ××•×¡×™×¤×™× ××ª ×”Ö¾Span ×œ×¨×©×™××ª ×”×™×©×•×™×•×ª `doc.ents`

---

### Sentence Segmentation

×¤×™×¦×•×œ ×”×˜×§×¡×˜ ×œ××©×¤×˜×™× ×”×•× ×©×œ×‘ ×—×©×•×‘ ×œ×¤× ×™ × ×™×ª×•×— ×˜×§×¡×˜. SpaCy ××©×ª××©×ª ×‘×¡×™×× ×™ ×¤×™×¡×•×§ (×›××• `.` `!` `?`) ×›×“×™ ×œ×§×‘×•×¢ ×”×™×›×Ÿ ××¡×ª×™×™× ××©×¤×˜.

```python
for sent in doc.sents:
    print(sent)
```

ğŸ“Œ × ×™×ª×Ÿ ×œ×’×©×ª ××œ ×›×œ ×”××©×¤×˜×™× ×‘×××¦×¢×•×ª `doc.sents`. ××š ×–×• ××™× ×” ×¨×©×™××”, ××œ× generator, ×œ×›×Ÿ × ×•×›×œ ×œ×”×¤×•×š ××•×ª×” ×œ×¨×©×™××” ×¢× `list(doc.sents)`

---

### Custom Segmentation Rules

×œ×¤×¢××™× × ×¨×¦×” ×©Ö¾SpaCy ×ª×¤×¨×™×“ ×’× ×œ×¤×™ ×¡×™×× ×™× ××—×¨×™× (×›××• `;`). × ×•×›×œ ×œ×”×•×¡×™×£ ×—×•×§ ××•×ª××:

```python
from spacy.language import Language

@Language.component("set_custom_boundaries")
def set_custom_boundaries(doc):
    for i, token in enumerate(doc[:-1]):
        if token.text == ";":
            doc[i + 1].is_sent_start = True
    return doc

nlp.add_pipe("set_custom_boundaries", before="parser")
```

ğŸ“Œ ×¤×•× ×§×¦×™×™×ª ×”×—×•×§ ××–×”×” ×ª×• ×›××• `;` ×•××¡×× ×ª ×©×”×˜×•×§×Ÿ ×”×‘× ××—×¨×™×• ×”×•× ×”×ª×—×œ×” ×©×œ ××©×¤×˜

---

### SpaCy Pipeline

Pipeline ×”×•× ×¨×¦×£ ×”×¤×¢×•×œ×•×ª ×©Ö¾SpaCy ××‘×¦×¢×ª ×¢×œ ×”×˜×§×¡×˜:

1. Tokenization
2. POS Tagging
3. Dependency Parsing
4. Lemmatization
5. Named Entity Recognition
6. Sentence Segmentation

×›×œ ×©×œ×‘ ××©×¤×™×¢ ×¢×œ ×”Ö¾`Doc` ×•××•×¡×™×£ ×œ×• ××™×“×¢. ××¤×©×¨ ×’× ×œ×”×•×¡×™×£ ×©×œ×‘×™× ××•×ª×××™× ×›××• segmentation ××• ×–×™×”×•×™ ×™×©×•×™×•×ª ××•×ª×××•×ª

ğŸ“Œ × ×™×ª×Ÿ ×œ×”×•×¡×™×£ ×©×œ×‘ ×¢× `add_pipe()` ××• ×œ×”×¡×™×¨ ×¢× `disable()`
