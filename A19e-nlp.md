# NLP FETAURES

## ××”×• ×§×•×¨×¤×•×¡ (Corpus)

×§×•×¨×¤×•×¡ ×”×•× ××•×¡×£ ×’×“×•×œ ×©×œ ×˜×§×¡×˜×™× ×”××©××© ×œ×œ×™××•×“ ×•× ×™×ª×•×— ×©×¤×” ×˜×‘×¢×™×ª. ×–×” ×™×›×•×œ ×œ×”×™×•×ª ×˜×§×¡×˜×™× ×¡×¤×¨×•×ª×™×™×, ×—×“×©×•×ª, ×ª××œ×•×œ×™× ×©×œ ×“×™×‘×•×¨, ××ª×¨×™ ××™× ×˜×¨× ×˜ ×•×¢×•×“

×‘×§×•× ×˜×§×¡×˜ ×©×œ NLP, ×§×•×¨×¤×•×¡ ××©××© ×œ××™××•×Ÿ, ×‘×“×™×§×” ×•×”×¢×¨×›×” ×©×œ ××•×“×œ×™× â€“ ×œ×“×•×’××”, ××•×“×œ×™× ×©×œ ×—×œ×§×™ ×“×™×‘×¨ (POS) ××• ×–×™×”×•×™ ×™×©×•×™×•×ª (NER)

#### ×¡×•×’×™ ×§×•×¨×¤×•×¡×™×:

* **×§×•×¨×¤×•×¡ ×œ× ××¡×•××Ÿ** (raw corpus): ×˜×§×¡×˜ ×¨×’×™×œ ×œ×œ× ×ª×™×•×’
* **×§×•×¨×¤×•×¡ ××¡×•××Ÿ** (annotated corpus): ×›×•×œ×œ ××™×“×¢ × ×•×¡×£ ×›××• ×—×œ×§×™ ×“×™×‘×¨, ×ª×—×‘×™×¨, ×™×©×•×™×•×ª ×•×›×•'

ğŸ“Œ ×”- SpaCy ××•×× ×” ×¢×œ ×§×•×¨×¤×•×¡×™× ××¡×•×× ×™×, ××” ×©×××¤×©×¨ ×œ×” ×œ×”×‘×™×Ÿ ×”×§×©×¨×™× ×•×œ×–×”×•×ª ××‘× ×™× ×œ×©×•× ×™×™× ××•×¨×›×‘×™×

**×“×•×’×× 1**

```python
import spacy
nlp = spacy.load('en_core_web_sm')
doc = nlp("The quick brown fox jumped over the lazy dog's back.")

print(doc[4].text, doc[4].pos_, doc[4].tag_, spacy.explain(doc[4].tag_))
```

Output:
```
jumped VERB VBD verb, past tense
```

SpaCy decided that the token jumped is a verb with the VBD tag, meaning it's a verb in past tense

**×“×•×’×× 2**

```python
doc1 = nlp(u'I read books on NLP.')
doc2 = nlp(u'I read a book on NLP.')

print(f'{doc1[1].text:10} {doc1[1].pos_:8} {doc1[1].tag_:6} {spacy.explain(doc1[1].tag_)}')
print()
print(f'{doc2[1].text:10} {doc2[1].pos_:8} {doc2[1].tag_:6} {spacy.explain(doc2[1].tag_)}')
```

Output:
```
read       VERB     VBP    verb, non-3rd person singular present

read       VERB     VBD    verb, past tense
```

ğŸ“Œ SpaCy is smart enough to understand from the textual context that the first read token is in present tense, while the second read is in past tense

## Named Entity Recognition (NER)

×”- NER ×”×•× ×ª×”×œ×™×š ×©×‘×• ××–×”×™× ×™×©×•×™×•×ª ×‘×©× ×‘×˜×§×¡×˜ (×›××• ×©××•×ª ×©×œ ×× ×©×™×, ××§×•××•×ª, ×—×‘×¨×•×ª, ×¡×›×•××™×, ×ª××¨×™×›×™× ×•×›×•')

#### â€¢ **Named Entities**  
×‘× ×™×™×ª ×¨×©×™××” ×©×œ ×™×©×•×™×•×ª ×‘×©× ××ª×•×š ×”×˜×§×¡×˜, ×›×©×”××¤×ª×— ×”×•× ×¡×•×’ ×”×™×©×•×ª ×•×”×¢×¨×›×™× ×”× ×”××•×¤×¢×™× ×©×–×•×”×•  
×œ×“×•×’××”:
- **Persons (PER)** â€“ ×©××•×ª ×©×œ ×× ×©×™× ×›××•: `"Albert Einstein"`, `"Marie Curie"`
- **Locations (LOC)** â€“ ××§×•××•×ª ×’×™××•×’×¨×¤×™×™× ×›××•: `"Paris"`, `"Mount Everest"`

#### â€¢ **Recognition**  
×–×™×”×•×™ ×‘×¤×•×¢×œ ×©×œ ×”××™×œ×™× ××• ×”×‘×™×˜×•×™×™× ×‘×˜×§×¡×˜ ×©××™×™×¦×’×™× ×™×©×•×™×•×ª ×‘×©×  
×œ×“×•×’××”: ×‘××©×¤×˜ `"Barack Obama visited Paris"` â€“ × ×–×”×” ××ª `"Barack Obama"` ×•××ª `"Paris"` ×›×™×©×•×™×•×ª

#### â€¢ **Classification**  
×©×™×•×š ×›×œ ×™×©×•×ª ×©× ××¦××” ×œ×§×˜×’×•×¨×™×” ××ª××™××” (×›××• `PERSON`, `LOCATION`, `ORG`, `DATE` ×•×›×•')


### ×©×œ×‘×™×:

1. **Tokenization** â€“ ×¤×™×¦×•×œ ×”×˜×§×¡×˜ ×œ××™×œ×™×
2. **Feature Extraction** â€“ ×”×¤×§×ª ×××¤×™×™× ×™× ×›××• ×¦×•×¨×ª ××™×œ×”, ××•×ª×™×•×ª ×’×“×•×œ×•×ª, ×¡×™×•××•×ª
3. **Model Training** â€“ ××™××•×Ÿ ××•×“×œ ×¢×œ ×˜×§×¡×˜×™× ××¡×•×× ×™× ××¨××©
4. **Prediction** â€“ ×–×™×”×•×™ ×™×©×•×™×•×ª ×‘×˜×§×¡×˜ ×—×“×©

`Barack Obama was born on August 4, 1961, in Honolulu, Hawaii.`

#### 1. **Tokenization** â€“ ×¤×™×¦×•×œ ×”×˜×§×¡×˜ ×œ××™×œ×™× (×˜×•×§× ×™×)  
×”- SpaCy ××¤×¨×§×ª ××ª ×”××©×¤×˜ ×œ××™×œ×™× ×•×ª×•×•×™ ×¤×™×¡×•×§ â€“ ×›××• `"Barack"`, `"Obama"`, `"August"`, `"4"`, `"1961"`, `","`, `"Hawaii"` ×•×›×•'

#### 2. **Feature Extraction** â€“ ×”×¤×§×ª ×××¤×™×™× ×™× ××”×˜×•×§× ×™×  
×œ×›×œ ××™×œ×” ××—×•×œ×¦×™× ×××¤×™×™× ×™× ×›××•:  
- ×”×× ×”××•×ª ×”×¨××©×•× ×” ×’×“×•×œ×”? (Barack)  
- ×”×× ×–×• ××™×œ×” ××¡×¤×¨×™×ª ××• ×ª××¨×™×š? (4, 1961)  
- ×”×× ×”×™× ×××•×§××ª ××—×¨×™ ××™×œ×ª ××¤×ª×— ×›××• "born on"?  

×××¤×™×™× ×™× ××œ×• ×¢×•×–×¨×™× ×œ××•×“×œ ×œ×”×‘×™×Ÿ ××™×œ×• ××™×œ×™× ×¢×©×•×™×•×ª ×œ×”×™×•×ª ×™×©×•×™×•×ª

#### 3. **Model Training** â€“ (×›×‘×¨ ×‘×•×¦×¢ ××¨××© ×¢×œ ×™×“×™ spaCy)  
×”××•×“×œ ×©××•××Ÿ ×¢×œ ×§×•×¨×¤×•×¡ ×’×“×•×œ ×™×•×“×¢ ×œ×–×”×•×ª ××‘× ×™× ×©×œ ×©××•×ª ×¤×¨×˜×™×™×, ×ª××¨×™×›×™×, ×¢×¨×™× ×•×¢×•×“

#### 4. **Prediction** â€“ ×—×™×–×•×™ ×”×™×©×•×™×•×ª ×‘×˜×§×¡×˜  
×”××•×“×œ ××–×”×” ××ª ×”×™×©×•×™×•×ª ×”×‘××•×ª:

```
Barack Obama â†’ PERSON â†’ ××“× (×××™×ª×™ ××• ×‘×“×™×•× ×™)
August 4, 1961 â†’ DATE â†’ ×ª××¨×™×š
Honolulu â†’ GPE â†’ ××“×™× ×” / ×¢×™×¨ / ××–×•×¨ ×’×™××•×’×¨×¤×™
Hawaii â†’ GPE â†’ ××“×™× ×” / ×¢×™×¨ / ××–×•×¨ ×’×™××•×’×¨×¤×™
```

ğŸ“Œ ×›×š spaCy ××¦×œ×™×—×” ×œ×”×‘×™×Ÿ ××ª×•×š ×”×”×§×©×¨ ×•×œ×¡×•×•×’ × ×›×•×Ÿ ×›×œ ×™×©×•×ª ×‘×˜×§×¡×˜

**×¤×™×™×ª×•×Ÿ**

```python
doc = nlp("Barack Obama was born on August 4, 1961, in Honolulu, Hawaii.")
for ent in doc.ents:
    print(ent.text, ent.label_, spacy.explain(ent.label_))
```

Output:
```
Barack Obama PERSON People, including fictional
August 4, 1961 DATE Absolute or relative dates or periods
Honolulu GPE Countries, cities, states
Hawaii GPE Countries, cities, states
```

ğŸ“Œ ×”- SpaCy ××—×–×™×¨ ×™×©×•×™×•×ª ×¢× label ×›××• `PERSON`, `DATE`, `GPE` ×•×××¤×©×¨ ×œ×”×¡×‘×™×¨ ×›×œ label ×‘×××¦×¢×•×ª `spacy.explain`

---

### ğŸ§  ×”×ª×××” ××™×©×™×ª ×©×œ NER ×‘Ö¾spaCy

#### ×œ××” × ×¨×¦×” ×œ×”×•×¡×™×£ ×™×©×•×™×•×ª ×™×“× ×™×ª?
×œ×¤×¢××™× spaCy ×œ× ××–×”×” ×™×©×•×™×•×ª ×©×× ×—× ×• ×›×Ÿ ×¨×•×¦×™× ×œ×–×”×•×ª â€“ ×œ×“×•×’××”, "Tesla" ×œ× ××–×•×”×” ×›×‘×¨×™×¨×ª ××—×“×œ ×›×™×©×•×ª ××¡×•×’ ORG  
×‘××§×¨×™× ×›××œ×” × ×•×›×œ ×œ×”×•×¡×™×£ ××ª ×”×™×©×•×ª ×™×“× ×™×ª ×œ××¡××š

#### ×”×©×œ×‘×™× ×œ×”×•×¡×¤×ª ×™×©×•×ª ×™×“× ×™×ª:
1. ×©×œ×™×¤×ª ×”×¢×¨×š ×”××¡×¤×¨×™ (hash) ×©×œ ×”×ª×•×•×™×ª ×”×¨×¦×•×™×” (×œ××©×œ "ORG")
2. ×™×¦×™×¨×ª Span ××”××™×œ×” ××• ×”×‘×™×˜×•×™ ×”×¨×¦×•×™
3. ×”×•×¡×¤×ª ×”Ö¾Span ×œ×¨×©×™××ª ×”×™×©×•×™×•×ª ×‘××¡××š `doc.ents`

```python
import spacy
nlp = spacy.load('en_core_web_sm')

doc = nlp(u'Tesla to build a U.K. factory for $6 million')
for ent in doc.ents:
    print(ent.text, ent.label_, spacy.explain(ent.label_))  


from spacy.tokens import Span

ORG = doc.vocab.strings["ORG"]
new_ent = Span(doc, start=0, end=1, label=ORG)
doc.ents = list(doc.ents) + [new_ent]

for ent in doc.ents:
    print(ent.text, ent.label_, spacy.explain(ent.label_))  
```

Output:
```
-Before
U.K. GPE Countries, cities, states
$6 million MONEY Monetary values, including unit

-After
Tesla ORG Companies, agencies, institutions, etc.
U.K. GPE Countries, cities, states
$6 million MONEY Monetary values, including unit
```

#### ×“×•×’××” ××ª×§×“××ª â€“ Phrase Matcher
×× × ×¨×¦×” ×œ×–×”×•×ª ×‘×™×˜×•×™×™× ×©×œ××™× ×›××•:
- `dashboard website`
- `dashboard-website`

× ×©×ª××© ×‘Ö¾PhraseMatcher ×œ×–×™×”×•×™ ×”×‘×™×˜×•×™×™× ×‘××¡××š, ×•××– × ×•×¡×™×£ ××•×ª× ×›×™×©×•×™×•×ª:

```python
from spacy.matcher import PhraseMatcher

matcher = PhraseMatcher(nlp.vocab)
patterns = [nlp("dashboard website"), nlp("dashboard-website")]
matcher.add("PRODUCT", patterns)

matches = matcher(doc)
new_ents = [Span(doc, start, end, label=doc.vocab.strings["PRODUCT"]) for match_id, start, end in matches]
doc.ents = list(doc.ents) + new_ents
```

#### ×©×™××•×©×™× × ×•×¡×¤×™×:
××¤×©×¨ ×’×:
- ×œ×¡×¤×•×¨ ×™×©×•×™×•×ª ×œ×¤×™ ×¡×•×’: `len([ent for ent in doc.ents if ent.label_ == "ORG"])`
- ×œ×”×¦×™×’ ××ª ×›×œ ×”×™×©×•×™×•×ª ×¢× ×”×¡×•×’×™× ×©×œ×”×Ÿ
- ×œ×”×“×¤×™×¡ ××ª ××™×§×•× ×”×”×ª×—×œ×” ×•×”×¡×™×•× ×©×œ ×›×œ ×™×©×•×ª

---A

### Sentence Segmentation

×¤×™×¦×•×œ ×”×˜×§×¡×˜ ×œ××©×¤×˜×™× ×”×•× ×©×œ×‘ ×—×©×•×‘ ×œ×¤× ×™ × ×™×ª×•×— ×˜×§×¡×˜. SpaCy ××©×ª××©×ª ×‘×¡×™×× ×™ ×¤×™×¡×•×§ (×›××• `.` `!` `?`) ×›×“×™ ×œ×§×‘×•×¢ ×”×™×›×Ÿ ××¡×ª×™×™× ××©×¤×˜.

```python
for sent in doc.sents:
    print(sent)
```

ğŸ“Œ × ×™×ª×Ÿ ×œ×’×©×ª ××œ ×›×œ ×”××©×¤×˜×™× ×‘×××¦×¢×•×ª `doc.sents`. ××š ×–×• ××™× ×” ×¨×©×™××”, ××œ× generator, ×œ×›×Ÿ × ×•×›×œ ×œ×”×¤×•×š ××•×ª×” ×œ×¨×©×™××” ×¢× `list(doc.sents)`

---

### Custom Segmentation Rules

×œ×¤×¢××™× × ×¨×¦×” ×©Ö¾SpaCy ×ª×¤×¨×™×“ ×’× ×œ×¤×™ ×¡×™×× ×™× ××—×¨×™× (×›××• `;`). × ×•×›×œ ×œ×”×•×¡×™×£ ×—×•×§ ××•×ª××:

```python
from spacy.language import Language

@Language.component("set_custom_boundaries")
def set_custom_boundaries(doc):
    for i, token in enumerate(doc[:-1]):
        if token.text == ";":
            doc[i + 1].is_sent_start = True
    return doc

nlp.add_pipe("set_custom_boundaries", before="parser")
```

ğŸ“Œ ×¤×•× ×§×¦×™×™×ª ×”×—×•×§ ××–×”×” ×ª×• ×›××• `;` ×•××¡×× ×ª ×©×”×˜×•×§×Ÿ ×”×‘× ××—×¨×™×• ×”×•× ×”×ª×—×œ×” ×©×œ ××©×¤×˜

---

### SpaCy Pipeline

Pipeline ×”×•× ×¨×¦×£ ×”×¤×¢×•×œ×•×ª ×©Ö¾SpaCy ××‘×¦×¢×ª ×¢×œ ×”×˜×§×¡×˜:

1. Tokenization
2. POS Tagging
3. Dependency Parsing
4. Lemmatization
5. Named Entity Recognition
6. Sentence Segmentation

×›×œ ×©×œ×‘ ××©×¤×™×¢ ×¢×œ ×”Ö¾`Doc` ×•××•×¡×™×£ ×œ×• ××™×“×¢. ××¤×©×¨ ×’× ×œ×”×•×¡×™×£ ×©×œ×‘×™× ××•×ª×××™× ×›××• segmentation ××• ×–×™×”×•×™ ×™×©×•×™×•×ª ××•×ª×××•×ª

ğŸ“Œ × ×™×ª×Ÿ ×œ×”×•×¡×™×£ ×©×œ×‘ ×¢× `add_pipe()` ××• ×œ×”×¡×™×¨ ×¢× `disable()`
