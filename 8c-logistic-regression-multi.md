# ğŸŒŸ ×¨×’×¨×¡×™×” ×œ×•×’×™×¡×˜×™×ª ×¢× ×›××” ××©×ª× ×™× (Multivariable Logistic Regression)

## ğŸ“˜ ××” ×–×” ×¨×’×¨×¡×™×” ×œ×•×’×™×¡×˜×™×ª?
×¨×’×¨×¡×™×” ×œ×•×’×™×¡×˜×™×ª ×”×™× ×©×™×˜×” ×¡×˜×˜×™×¡×˜×™×ª ×œ×—×™×–×•×™ ××©×ª× ×” ×ª×œ×•×™ ×‘×™× ××¨×™ ××• ×¨×‘Ö¾×§×˜×’×•×¨×™ (×›××•: ×›×Ÿ/×œ×, ×¡×•×’ ×¤×¨×—), ×¢×œ ×¡××š ×¢×¨×›×™× ×©×œ ××©×ª× ×™× ××¡×‘×™×¨×™× (×ª×›×•× ×•×ª).

×‘××§×¨×” ×©×œ ××¡×¤×¨ ××©×ª× ×™× ××¡×‘×™×¨×™× (features), ××“×•×‘×¨ ×‘×¨×’×¨×¡×™×” ×œ×•×’×™×¡×˜×™×ª ×¢× **×›××” × ×¢×œ××™×**.

---

## âœï¸ ××•×©×’×™× ×‘×¡×™×¡×™×™×:

- **××©×ª× ×” ×ª×œ×•×™ (Y):** ××” ×©×× ×—× ×• ×× ×¡×™× ×œ×—×–×•×ª (×œ××©×œ ×¡×•×’ ×¤×¨×—)
- **××©×ª× ×™× ×‘×œ×ª×™ ×ª×œ×•×™×™× (Xâ‚, Xâ‚‚, Xâ‚ƒ...):** ×”×ª×›×•× ×•×ª ×©××¡×‘×™×¨×•×ª ××ª Y (×œ××©×œ ××•×¨×š ×¢×œ×™ ×›×•×ª×¨×ª)
- **Î² (×‘×˜×):** ××§×“××™× ×©× ×œ××“×™× ×¢×œ ×™×“×™ ×”××•×“×œ. ×›×œ ××©×ª× ×” ××§×‘×œ Î² ××©×œ×•.

---

## ğŸ“ × ×•×¡×—×” ××ª××˜×™×ª (Softmax Multiclass):

×× ×™×© ×œ× ×• \( K \) ×§×˜×’×•×¨×™×•×ª ×•Ö¾\( n \) ××©×ª× ×™×:

\[
P(y = k \mid x) = \frac{e^{\beta_{k0} + \beta_{k1}x_1 + \beta_{k2}x_2 + \dots + \beta_{kn}x_n}}{\sum_{j=1}^K e^{\beta_{j0} + \beta_{j1}x_1 + \beta_{j2}x_2 + \dots + \beta_{jn}x_n}}
\]

- ×–×•×”×™ ×¤×•× ×§×¦×™×™×ª **Softmax** â€“ ×××™×¨×” ××ª ×”×¦×™×•× ×™× ×œ×”×¡×ª×‘×¨×•×™×•×ª.
- ×›×œ ×§×˜×’×•×¨×™×” ××§×‘×œ×ª ×”×¡×ª×‘×¨×•×ª, ×•×”×—×–×•×™×” ×”×™× ×–×• ×¢× ×”×”×¡×ª×‘×¨×•×ª ×”×’×‘×•×”×” ×‘×™×•×ª×¨.

---

## ğŸŒ¸ ×“×•×’××” â€“ ×¢×œ ×‘×¡×™×¡ × ×ª×•× ×™ Iris:

× × ×¡×” ×œ×—×–×•×ª ××ª ×¡×•×’ ×”×¤×¨×— (setosa, versicolor, virginica) ×¢×œ ×¡××š 4 ××©×ª× ×™×:
- sepal length (Xâ‚)
- sepal width (Xâ‚‚)
- petal length (Xâ‚ƒ)
- petal width (Xâ‚„)

×›×œ ×¡×•×’ ×¤×¨×— ×™×§×‘×œ ××§×“××™× ××©×œ×•:

×œ××©×œ:

\[
P(y = \text{setosa}) = \frac{e^{\beta_{0} + \beta_1 x_1 + \beta_2 x_2 + \beta_3 x_3 + \beta_4 x_4}}{\text{sum of all classes}}
\]

---

## ğŸ§ª ×§×•×“ ×¤×™×™×ª×•×Ÿ ×œ×“×•×’××”:

```python
import pandas as pd
from sklearn.linear_model import LogisticRegressionCV
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report

# Load dataset
df = pd.read_csv("iris.csv")
X = df.drop(columns="species")  # Features
y = df["species"]               # Target (3 flower types)

# Train/test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Normalize features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Train logistic regression with multinomial softmax
model = LogisticRegressionCV(
    solver='lbfgs',           # Efficient for multiclass problems
    multi_class='multinomial',# Uses softmax across all classes
    cv=5,
    max_iter=500
)
model.fit(X_train_scaled, y_train)

# Predict and evaluate
y_pred = model.predict(X_test_scaled)
print(classification_report(y_test, y_pred))
